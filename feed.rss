<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content"><channel><title>JimLearningBlog</title><description>A description of JimLearningBlog</description><link>https://jimlearning.github.io</link><language>zh</language><lastBuildDate>Fri, 12 Mar 2021 01:16:14 +0800</lastBuildDate><pubDate>Fri, 12 Mar 2021 01:16:14 +0800</pubDate><ttl>250</ttl><atom:link href="https://jimlearning.github.io/feed.rss" rel="self" type="application/rss+xml"/><item><guid isPermaLink="true">https://jimlearning.github.io/tips/script-with-go</guid><title>Script with Go</title><description>Learn how to run executable scripts in Go.</description><link>https://jimlearning.github.io/tips/script-with-go</link><pubDate>Mon, 9 Mar 2020 06:25:00 +0800</pubDate><content:encoded><![CDATA[<h2>Prerequisites</h2><p>To keep things simple we will assume you have access to a machine running macOS or Linux and have already installed <a href="https://golang.org/">Go</a> and <a href="https://github.com/erning/gorun">Gorun</a>.</p><h2>How to script with Go</h2><img src="https://jimlearning.github.io/images/posts/go-logo.svg" alt="Go logo"/><p>If you are already a Go developer, you should be familiar with the process of creating a Go package, application or command line tool. Once you have created one of these you would usually need to build a binary and then place it in a executable path before it can be run from a Command Line Interface (CLI). Sometimes, however, we just want to write a script and execute it as is, rather than package it for deployment. This can be particularly useful if you'd like to use Go in different stages of the software development lifecycle such as inside of your Continuous Integration or Continuous Deployment pipelines.</p><p>In such pipelines, it's typical to create a bash file and execute it. For example you could create a file called <code>hello-world</code> with the following contents:</p><pre><code>#!/usr/bin/env bash

echo <span class="string">"Hello, World!"</span>
</code></pre><p>You would then make it executable by running:</p><pre><code>chmod +x hello-world
</code></pre><p>And then execute it by running:</p><pre><code>./hello-world
</code></pre><p>But this is not just limited to runtime languages like bash, the comment on the first line tells the machine what program to use when interpreting the file. This means we can create and execute a script using the Go programming language instead. For example, let's replace the contents of the <code>hello-world</code> file we created earlier with this:</p><pre><code>#! /usr/bin/env gorun

package main

<span class="keyword">import</span> <span class="string">"fmt"</span>

<span class="keyword">func</span> main() {
	fmt.<span class="type">Printf</span>(<span class="string">"hello, world\n"</span>)
}
</code></pre><p>Now you can execute the script by running the same command as we did earlier:</p><pre><code>./hello-world
</code></pre><p>Once again you should see the text <code>Hello, World!</code> printed to the console.</p><h2>Summary</h2><p>That's it! In this post we have demonstrated a simple way to build small Go scripts that you can modify and run in place whenever you need to, without the need to recompile and deploy them.</p><h2>References</h2><ul><li><a href="https://golang.org/ "golang.org"">Go</a></li><li><a href="https://gist.github.com/posener/73ffd326d88483df6b1cb66e8ed1e0bd "Story: Writing Scripts with Go"">Writing Scripts with Go</a></li></ul>]]></content:encoded></item><item><guid isPermaLink="true">https://jimlearning.github.io/articles/vapor-mongo-api</guid><title>Creating Swift microservices using Vapor and MongoDB</title><description>Learn how to create a server-side RESTful API using Swift and Vapor backed with a NoSQL database for storage and run it all using Docker.</description><link>https://jimlearning.github.io/articles/vapor-mongo-api</link><pubDate>Sun, 2 Feb 2020 06:00:00 +0800</pubDate><content:encoded><![CDATA[<h2>Prerequisites</h2><p>To keep things simple we will assume you have access to a machine running macOS or Linux and have already installed Curl, Swift, Vapor and Docker.</p><h2>Creating a MongoDB instance</h2><p>For this tutorial we will need to setup a local MongoDB instance that we can use for our Todo API. The following command starts a MongoDB container instance, allowing us to execute MongoDB statements against a database instance:</p><pre><code>docker run -d \
  --name mongodb \
  -p <span class="number">27017</span>-<span class="number">27019</span>:<span class="number">27017</span>-<span class="number">27019</span> \
  -v ~/data:/data/db \
  mongo:latest
</code></pre><h2>Creating a Vapor project</h2><p>For this post we will make use of the built in Vapor code generator to create a simple RESTful API for creating, reading, updating and deleting todos. Use vapor to create a new project by running the following command:</p><pre><code>vapor new vapor-todo-api
</code></pre><p>Once the project files have been generated, navigate into the directory by running:</p><pre><code>cd vapor-todo-api
</code></pre><p>In order to connect our Vapor application to a MongoDB database we have to modify some of the generated code to remove the use of SQLite. Let's replace the SQLite dependency and target with MeowVapor inside the <code>Package.swift</code> file:</p><pre><code><span class="comment">// swift-tools-version:4.0</span>
<span class="keyword">import</span> PackageDescription

<span class="keyword">let</span> package = <span class="type">Package</span>(
    name: <span class="string">"vapor-todo-api"</span>,
    products: [
        .<span class="call">library</span>(
            name: <span class="string">"vapor-todo-api"</span>, 
            targets: [<span class="string">"App"</span>]
        ),
    ],
    dependencies: [
        <span class="comment">// ðŸ’§ A server-side Swift web framework.</span>
        .<span class="call">package</span>(
            url: <span class="string">"https://github.com/vapor/vapor.git"</span>, 
            from: <span class="string">"3.0.0"</span>
        ),

        <span class="comment">// ðŸ”µ Swift ORM (queries, models, relations, etc) built on Meow, MongoKitten.</span>
        .<span class="call">package</span>(
            url: <span class="string">"https://github.com/OpenKitten/MeowVapor.git"</span>, 
            from: <span class="string">"2.1.2"</span>
        )
    ],
    targets: [
        .<span class="call">target</span>(
            name: <span class="string">"App"</span>, 
            dependencies: [
                <span class="string">"MeowVapor"</span>, 
                <span class="string">"Vapor"</span>
            ]
        ),
        .<span class="call">target</span>(
            name: <span class="string">"Run"</span>, 
            dependencies: [
                <span class="string">"App"</span>
            ]
        ),
        .<span class="call">testTarget</span>(
            name: <span class="string">"AppTests"</span>, 
            dependencies: [
                <span class="string">"App"</span>
            ]
        )
    ]
)
</code></pre><p>MeowVapor is a wrapper for Meow and MongoKitten and provides us with a boiletplate-free object persitance framework for MongoDB and Swift, freeing us from the need to manage our database. After adding this dependancy we need to modify the generated <code>Sources/App/configure.swift</code> file in order to set up the MongoDB driver instead of the default SQLite one. We are going to start by setting the database connection details based on an environment variable <code>MONGODB_URI</code>:</p><pre><code><span class="keyword">import</span> MeowVapor
<span class="keyword">import</span> Vapor

<span class="comment">// Called before your application initializes.</span>
<span class="keyword">public func</span> configure(
    <span class="keyword">_</span> config: <span class="keyword">inout</span> <span class="type">Config</span>, 
    <span class="keyword">_</span> env: <span class="keyword">inout</span> <span class="type">Environment</span>, 
    <span class="keyword">_</span> services: <span class="keyword">inout</span> <span class="type">Services</span>) <span class="keyword">throws</span> {
    
    <span class="keyword">let</span> uri = <span class="type">Environment</span>.<span class="call">get</span>(<span class="string">"MONGODB_URI"</span>)
        ?? <span class="string">"mongodb://localhost/tododb"</span>

    <span class="comment">// Configure a MongoDB database</span>
    <span class="keyword">let</span> meow = <span class="keyword">try</span> <span class="type">MeowProvider</span>(uri: uri)
    
    <span class="comment">// Register providers first</span>
    <span class="keyword">try</span> services.<span class="call">register</span>(meow)

    <span class="comment">// Register routes to the router</span>
    <span class="keyword">let</span> router = <span class="type">EngineRouter</span>.<span class="call">default</span>()
    <span class="keyword">try</span> <span class="call">routes</span>(router)
    services.<span class="call">register</span>(router, as: <span class="type">Router</span>.<span class="keyword">self</span>)

    <span class="comment">// Register middleware</span>
    <span class="keyword">var</span> middlewares = <span class="type">MiddlewareConfig</span>()
    middlewares.<span class="call">use</span>(<span class="type">ErrorMiddleware</span>.<span class="keyword">self</span>)
    services.<span class="call">register</span>(middlewares)
}
</code></pre><p>Next, we need to change to the <code>Sources/Models/Todo.swift</code> file so that our Todo model includes an attributed called <code>_id</code> which will be used to store a unique identifier of the type <code>ObjectId</code> for our MongoDB documents:</p><pre><code><span class="keyword">import</span> MeowVapor
<span class="keyword">import</span> Vapor

<span class="comment">// A single entry of a Todo list.</span>
<span class="keyword">final class</span> Todo: <span class="type">Model</span> {
    
    <span class="comment">// A unique identifier for the `Todo`</span>
    var _id: <span class="type">ObjectId</span>

    <span class="comment">// A title describing what this `Todo` entails.</span>
    <span class="keyword">var</span> title: <span class="type">String</span>

    <span class="comment">// Creates a new `Todo`.</span>
    <span class="keyword">init</span>(_id: <span class="type">ObjectId</span>, title: <span class="type">String</span>) {
        <span class="keyword">self</span>.<span class="property">_id</span> = _id
        <span class="keyword">self</span>.<span class="property">title</span> = title
    }
    
    <span class="comment">// Creates a new `Todo`.</span>
    <span class="keyword">init</span>(title: <span class="type">String</span>) {
        <span class="keyword">self</span>.<span class="property">_id</span> = <span class="type">ObjectId</span>()
        <span class="keyword">self</span>.<span class="property">title</span> = title
    }
}

<span class="comment">// Allows `Todo` to be encoded to and decoded from HTTP messages.</span>
<span class="keyword">extension</span> <span class="type">Todo</span>: <span class="type">Content</span> { }

<span class="comment">// Allows `Todo` to be used as a dynamic parameter in route definitions.</span>
<span class="keyword">extension</span> <span class="type">Todo</span>: <span class="type">Parameter</span> {}
</code></pre><p>Then we need to update our routes inside the <code>Sources/App/routes.swift</code> file to support the GET, POST, PUT end DELETE methods for the Todo's endpoint:</p><pre><code><span class="keyword">import</span> Vapor
<span class="keyword">import</span> MeowVapor

<span class="comment">// Register your application's routes here.</span>
<span class="keyword">public func</span> routes(<span class="keyword">_</span> router: <span class="type">Router</span>) <span class="keyword">throws</span> {
    <span class="keyword">let</span> todoController = <span class="type">TodoController</span>()
    
    router.<span class="call">get</span>(<span class="string">"todos"</span>, use: todoController.<span class="property">index</span>)
    router.<span class="call">post</span>(<span class="string">"todos"</span>, use: todoController.<span class="property">create</span>)
    router.<span class="call">put</span>(<span class="string">"todos"</span>, use: todoController.<span class="property">upsert</span>)
    router.<span class="call">delete</span>(<span class="string">"todos"</span>, <span class="type">Todo</span>.<span class="property">parameter</span>, use: todoController.<span class="property">delete</span>)
}
</code></pre><p>Lastly we will need to build and run our application. To create a Docker image containing our Vapor project, we can use the <code>web.Dockerfile</code> file that was automatically generated for us by running the following command:</p><pre><code>docker build --build-arg env=docker -t vapor-todo-api-image -f web.<span class="type">Dockerfile</span>
</code></pre><p>This command may take some time to finish, but when complete we will have made a Docker image containing our compiled Vapor project. The container can be run using the command:</p><pre><code>docker run --name vapor-todo-api -p <span class="number">8080</span>:<span class="number">80</span> vapor-todo-api-image
</code></pre><h2>Testing the Todo API</h2><p>Now that we have a running instance of a MongoDB database and our API, let's test it to ensure it works as expected. To insert a new Todo we can call the POST endpoint that we created using the Curl command:</p><pre><code>curl -<span class="type">X POST</span> \
  -<span class="type">H</span> <span class="string">"Content-Type: application/json"</span> -d '{<span class="string">"_id"</span>:<span class="string">"5e36366465da966614a18f46"</span>, <span class="string">"title"</span>:<span class="string">"My todo!"</span>}' \
   localhost/todos
</code></pre><p>After running this command you should recieve a copy of the created Todo in the API response:</p><pre><code>{<span class="string">"_id"</span>:<span class="string">"5e36366465da966614a18f46"</span>, <span class="string">"title"</span>:<span class="string">"My todo!"</span>}
</code></pre><p>To verify that our Todo was indeed created, we can use our GET endpoint:</p><pre><code>curl -<span class="type">X GET</span> localhost/todos
</code></pre><p>This should print the following to the screen:</p><pre><code>[{<span class="string">"_id"</span>:<span class="string">"5e36366465da966614a18f46"</span>,<span class="string">"title"</span>:<span class="string">"My Todo!"</span>}
</code></pre><p>Now that we have verified our Todo was indded created, lets replace it using our PUT endpoint by running:</p><pre><code>curl -<span class="type">X PUT</span> \
  -<span class="type">H</span> <span class="string">"Content-Type: application/json"</span> -d '{<span class="string">"_id"</span>:<span class="string">"5e36366465da966614a18f46"</span>, <span class="string">"title"</span>:<span class="string">"My updated todo!"</span>}' \
  localhost/todos
</code></pre><p>You should recieve a copy of the updated Todo in the API response:</p><pre><code>{<span class="string">"_id"</span>:<span class="string">"5e36366465da966614a18f46"</span>, <span class="string">"title"</span>:<span class="string">"My updated todo!"</span>}
</code></pre><p>Finally we can delete our Todo using our DELETE endpoint by running:</p><pre><code>curl -<span class="type">X DELETE</span> localhost/todos/5e36366465da966614a18f48
</code></pre><p>This should return a HTTP 200 response.</p><h2>Summary</h2><p>That's it! In this post we have demonstrated how to build an RESTful API in Swift that allows you to create, read, update and delete Todo's inside of a MongoDB database. Future posts will look at how we can deploy microservices using kubernetes.</p><h2>References</h2><ul><li><a href="https://swift.org/ "swift.org"">Swift</a></li><li><a href="https://vapor.codes "vapor.codes"">Vapor</a></li><li><a href="https://docs.docker.com/get-started/ "Docker"">Docker - Get Started</a></li></ul>]]></content:encoded></item><item><guid isPermaLink="true">https://jimlearning.github.io/tips/script-with-swift</guid><title>Script with Swift</title><description>Learn how to run executable scripts in Swift.</description><link>https://jimlearning.github.io/tips/script-with-swift</link><pubDate>Tue, 28 Jan 2020 06:00:00 +0800</pubDate><content:encoded><![CDATA[<h2>Prerequisites</h2><p>To keep things simple we will assume you have access to a machine running macOS or Linux and have already installed Swift.</p><h2>How to script with swift</h2><img src="https://jimlearning.github.io/images/posts/swift-logo.svg" alt="Swift logo"/><p>If you are already a Swift developer, you should be familiar with the process of creating a Swift package, application or command line tool. Once you have created one of these you would usually need to build a binary and then place it in a executable path before it can be run from a Command Line Interface (CLI). Sometimes, however, we just want to write a script and execute it as is, rather than package it for deployment. This can be particularly useful if you'd like to use Swift in different stages of the software development lifecycle such as inside of your Continuous Integration or Continuous Deployment pipelines.</p><p>In such pipelines, it's typical to create a bash file and execute it. For example you could create a file called <code>hello-world</code> with the following contents:</p><pre><code>#!/usr/bin/env bash

echo <span class="string">"Hello, World!"</span>
</code></pre><p>You would then make it executable by running:</p><pre><code>chmod +x hello-world
</code></pre><p>And then execute it by running:</p><pre><code>./hello-world
</code></pre><p>But this is not just limited to runtime languages like bash, the comment on the first line tells the machine what program to use when interpreting the file. This means we can create and execute a script using the Swift programming language instead. For example, let's replace the contents of the <code>hello-world</code> file we created earlier with this:</p><pre><code>#!/usr/bin/env swift

<span class="call">print</span>(<span class="string">"Hello, World!"</span>)
</code></pre><p>Now you can execute the script by running the same command as we did earlier:</p><pre><code>./hello-world
</code></pre><p>Once again you should see the text <code>Hello, World!</code> printed to the console.</p><h2>Summary</h2><p>That's it! In this post we have demonstrated a simple way to build small Swift scripts that you can modify and run in place whenever you need to, without the need to recompile and deploy them.</p><h2>References</h2><ul><li><a href="https://swift.org/ "swift.org"">Swift</a></li></ul>]]></content:encoded></item><item><guid isPermaLink="true">https://jimlearning.github.io/articles/containerise-vapor</guid><title>Containerising a Vapor application</title><description>Learn how to generate and containerise a server-side API using Swift and Vapor inside of a Docker container.</description><link>https://jimlearning.github.io/articles/containerise-vapor</link><pubDate>Mon, 27 Jan 2020 06:00:00 +0800</pubDate><content:encoded><![CDATA[<h2>Prerequisites</h2><p>To keep things simple, we will assume you have already installed the following: <em> Docker </em> Swift * Brew</p><p>My setup instructions are based macOS, but you can follow along on Linux as well.</p><h2>What is Vapor?</h2><img src="https://jimlearning.github.io/images/posts/vapor-logo.svg" alt="Vapor logo"/><p>Vapor is an open source web framework written in Swift. It can be used to create RESTful APIs, web apps and real-time applications using WebSockets. It is particularly geared towards projects that utilise the Model View Controller (MVC) style design pattern.</p><p>To learn more about Vapor, visit <a href="https://vapor.codes">vapor.codes</a></p><h2>Installing Vapor</h2><p>Installing Vapor is a relativly straightforward, it can be done by running the following commands in your preferred Command Line Interface (CLI):</p><pre><code>brew tap vapor/tap
brew install vapor/tap/vapor
</code></pre><p>Once complete, you can verify that Vapor was installed correctly by running:</p><pre><code>vapor --help
</code></pre><p>This should print a list of command options to the screen.</p><h2>Creating a Vapor project</h2><p>Vapor is easy to get started with, for this post we will make use of the built in code generator to create a simple Hello World application. Use the vapor executable we installed to create a new project by running the following command:</p><pre><code>vapor new hello-world
</code></pre><p>Once the project files have been generated, navigate into the directory by running:</p><pre><code>cd hello-world
</code></pre><h2>Creating a Docker Image</h2><p>To create a Docker image containing the Vapor project, we can use the <code></code><code>web.Dockerfile</code><code></code> file that was generated by running the following command:</p><pre><code>docker build --build-arg env=docker -t vapor-image -f web.<span class="type">Dockerfile</span>
</code></pre><p>This command may take some time to finish, but when complete we will have made a Docker image containing our compiled Vapor project. To run the Docker container and our project we can use the following command:</p><pre><code>docker run --name vapor-server -p <span class="number">8080</span>:<span class="number">80</span> vapor-image
</code></pre><p>Docker will run the container and bind port 80 inside of the container to port 8080 on your local machine. If you go to your browser and enter <a href="http://localhost:8080/hello">http://localhost:8080/hello</a>, you'll see that Vapor is running inside your container... <code>Hello, World!</code></p><h2>Summary</h2><p>Thats It! In this post we have demonstrated how easy it is to get started with Vapor by generating a server-side Swift project. When then illustrated how that project can be compiled and hosted inside of a Docker container. In future posts we will look at how we can expand on this example to develop Swift mircroservices.</p><h2>References</h2><ul><li><a href="https://swift.org/ "swift.org"">Swift</a></li><li><a href="https://vapor.codes "vapor.codes"">Vapor</a></li></ul>]]></content:encoded></item><item><guid isPermaLink="true">https://jimlearning.github.io/articles/swift-in-a-container</guid><title>How to run Swift in a Docker container</title><description>Learn how to run Swift inside a Docker container. Useful if you don't always have access to a machine running macOS or Linux to compile your code.</description><link>https://jimlearning.github.io/articles/swift-in-a-container</link><pubDate>Sun, 26 Jan 2020 06:00:00 +0800</pubDate><content:encoded><![CDATA[<h2>Prerequisites</h2><p>To keep things simple, we will assume you have access to a bash Command Line Interface (CLI) on your local machine. Linux and macOS users should have access to a <em>Terminal</em> application while Windows users will need to install one of several options, including but not limited to:</p><ul><li><a href="https://docs.microsoft.com/en-us/windows/wsl/install-win10">Windows subsystem for Linux</a></li><li><a href="https://gitforwindows.org">Git for Windows (Git Bash)</a></li></ul><p>We will also assume that you have already installed Docker. If you want to get started with Docker on a Windows 10 or Mac OS operating system, installing Docker Desktop is the quickest way.</p><h2>What is Swift?</h2><img src="https://jimlearning.github.io/images/posts/swift-logo.svg" alt="Swift logo"/><p>Swift is a compiled programming language for writing iOS, macOS, watchOS, tvOS and Linux applications. It was originally created by Apple in 2014 as an open source, type-safe, extensible and fast programming language with a modern syntax.</p><p>To learn more about Swift, visit <a href="https://swift.org">swift.org</a></p><h2>Why run Swift inside docker?</h2><img src="https://jimlearning.github.io/images/posts/docker-logo.svg" alt="Docker logo"/><p>You can compile and run Swift anywhere that you can install the Swift Compiler. At present this means you either need to have access to a machine running macOS or Linux. For those with a Windows machine, or perhaps working in a corporate environment where you are unable to install the Swift Compiler locally, you can look to Docker for a solution. With Docker we can easily run an official Swift image to allow us to easily compile and run our code in an independent and isolated environment. This can also be useful for portability, as Docker will help us ensure that our Swift code will run the same locally as it would when it's deployed to a server or the cloud.</p><h2>How to run swift in a Docker container?</h2><p>To begin with, we will need a simple Swift file that we can use to compile and run. Following tradition, lets create a file called <code>hello world.swift</code> containing the following:</p><pre><code><span class="keyword">import</span> Swift
<span class="call">print</span>(<span class="string">"Hello, world!"</span>)
</code></pre><p>This should print the words "Hello, world!" on the screen when run.</p><h3>Creating a Swift container</h3><p>Next, we will need to create a file called <code>Dockerfile</code> in our working directory. A Dockerfile has a file format that contains instructions and arguments, which define the contents and startup behaviour of the Docker container. The docker container we will create will run the Swift Compiler ontop of a Linux distribution and allow us to begin programming using Swift even on a Windows machine. To run our simple <code>hello world.swift</code> file, our Dockerfile will need to contain the following:</p><pre><code># <span class="type">The</span> first instruction <span class="keyword">in</span> a <span class="type">Dockerfile</span> must be <span class="type">FROM</span>, which selects a base image. <span class="type">Since</span> it's recommended to use official <span class="type">Docker</span> images, we will use the official image
<span class="type">FROM</span> swift

# <span class="type">Use</span> the <span class="type">WORKDIR</span> instruction to <span class="keyword">set</span> the working directory, which we will use to store the code we want to run
<span class="type">WORKDIR</span> /app

# <span class="type">Use</span> the <span class="type">ADD</span> instruction to copy our source code from the current directory into the working directory
<span class="type">ADD</span> . ./

# <span class="type">Run</span> the <span class="type">Swift</span> exectutable when the container <span class="keyword">is</span> started
<span class="type">ENTRYPOINT</span> [<span class="string">"swift"</span>]
</code></pre><p>The above Docker file will create an image based on the official Swift Docker image. When the image is built, it will copy the contents of the local directory into a folder named <code>/app</code> inside the image. This allows us to access and run the file inside the container.</p><p>To build an image containing our simple <code>hello world.swift</code> file, we can run the following command:</p><pre><code>docker build \
  -t my-swift-image .
</code></pre><p>Thats it! We've made a Docker image containing Swift and our <code>hello world.swift</code> file. To run our Docker container and execute the <code>hello world.swift</code> file, run the following command:</p><pre><code>docker run \
  --rm my-swift-image \
  <span class="string">"hello world.swift"</span>
</code></pre><p>You should now see <code>Hello, world!</code> printed on the terminal... But wait, doesn't that mean each time we make a change to our code we will have to re-build the docker image? While we certainally could do this, it wouldn't be the most efficient method available to us.</p><h3>Editing Swift code inside of our Docker container on-the-fly</h3><p>Instead of re-building our custom Docker image each time we change our code, we can run it and attach the local directory to it. To demonstrate that this is possible, lets begin with making a small change to our <code>hello world.swift</code> file. Change its contents to the following so that it will print a different line to the screen:</p><pre><code><span class="keyword">import</span> Swift
<span class="call">print</span>(<span class="string">"Hello, cruel world!"</span>)
</code></pre><p>Using the following command to start a container with our custom image, attach the current directory to the <code>/app</code> folder and execute the <code>hello world.swift</code> file we just modified:</p><pre><code>docker run -it \
  --rm -v $(pwd):/app \
  my-swift-image \
  <span class="string">"hello world.swift"</span>
</code></pre><p>You should now see <code>Hello, cruel world!</code> printed to the terminal!</p><h3>Using Swift interactivly inside a Docker container</h3><p>Another option would be to use the official Swift image instead of our custom one. To start a container with the official Swift Docker image, you can run the following command:</p><pre><code>docker run -it \
  --rm -v <span class="string">"$(pwd)"</span>:/app \
  swift
</code></pre><p>This will create a temporary container running Swift in interactive mode, allowing you to execute Swift commands inside a terminal environment. Lets tell Swift to execute our <code>hello world.swift</code> file by using the following command:</p><pre><code>swift run <span class="string">"/app/hello world.swift"</span>
</code></pre><p>Once again you should see <code>Hello, cruel world!</code> printed to the terminal.</p><h2>Summary</h2><p>Thats it! In this post we have demonstrated how easy it is to run swift code inside a Docker container. In future posts we will look at how we can containerise and run server-side Swift applications.</p><h2>References</h2><ul><li><a href="https://swift.org/ "swift.org"">Swift</a></li></ul>]]></content:encoded></item><item><guid isPermaLink="true">https://jimlearning.github.io/tips/books</guid><title>Recommended books</title><description>Great books for learning more about development and integration.</description><link>https://jimlearning.github.io/tips/books</link><pubDate>Sat, 14 Dec 2019 06:00:00 +0800</pubDate><content:encoded><![CDATA[<h2>Fiction</h2><p>The below books portray science and technology in a very idealised way and might use a bit of artistic license to keep readers engaged. They can be good to take you back to your roots, give you a new perspective or just for some quick entertainment.</p><ul><li><a href="https://store.xkcd.com/pages/if-you-re-looking-for-the-what-if-book">What If? Serious Scientific Answers to Absurd Hypothetical Questions</a>: If you've ever wanted answers to questions such as "How much computing power could we could achieve if the entire world population stopped whatever we are doing right now and started doing calculations? How would it compare to a modern-day computer or smartphone?" then this book is for you.</li></ul><h2>Non-Fiction</h2><p>These books are great when it comes to self-learning and improving your own skillset.</p><ul><li><a href="http://wiki.c2.com/?DesignPatternsBook">Design Patterns: Elements of Reusable Object-Oriented Software</a>: Otherwise known as the Gang of Four book, this is hands down the best book ever written on object-oriented design and has been very influential in the software development field. This book is a great introduction to software design and architecture for developers.</li><li><a href="https://martinfowler.com/books/refactoring.html">Refactoring</a>: This book by Martin Fowler and Kent Beck acts as a guide to making decisions around when and how to refactor code to keep it cheap and easy to modify to meet future needs.</li><li><a href="https://agilemanifesto.org/principles.html">Principles behind the Agile Manifesto</a>: I still find it amazing the amount of development teams that I come across who claim to be following an Agile Methodology but who havent read the twelve principles behind the Agile Manifesto. I recommend this short read to anyone working in an agile team, particularly those having dificulties achieving results.</li></ul>]]></content:encoded></item><item><guid isPermaLink="true">https://jimlearning.github.io/tips/git-aliases</guid><title>Git Aliases</title><description>In this post we will walk through how you can make your git workflow experience simpler and easier with aliases.</description><link>https://jimlearning.github.io/tips/git-aliases</link><pubDate>Fri, 13 Dec 2019 06:00:00 +0800</pubDate><content:encoded><![CDATA[<h2>Prerequisites</h2><p>To keep things brief, we will assume you already have Git installed and setup correctly.</p><h2>What is a Git Alias?</h2><p>An alias in Git is synonomous with a shortcut and is similar to <em>aliases</em> found in command processors such as <em>Bash</em>. They can be used to map long, complicated or hard to remember commands into shorter and easier to remember ones that require fewer keystrokes. For example, consider the <code>git push</code> command. It is frequently used to check in your staged changes, but instead of typing in the word <code>commit</code> an alias could be created to shorten it to <code>c</code> allowing <code>git c</code> to be typed instead. This can be a life changer for longer commands which can be particularly verbose.</p><h2>How to create a Git Alias</h2><p>Git Aliasss can be created using the <code>git config</code> command in either a local or global scope. To create an alias for commit which you can use in any repository, you can run the following command in your preferred Command Line Interface (CLI):</p><pre><code>git config --global alias.<span class="property">c</span> commit
</code></pre><p>The previous example can also be modified to use the <code>--local</code> flag instead of <code>--global</code> and run from inside of a repository to create a shortcut for just that repository instead any repository, like so:</p><pre><code>git config --local alias.<span class="property">c</span> commit
</code></pre><p>When the <code>config</code> command was run with the <code>--global</code> flag, Git created or modified the <code>.gitconfig</code> file, which is a hidden file typically located in your User home directory at <code>~/.gitconfig</code><code></code>. If you were to inspect the contents of this file, you would see an alias section that looks something like this:</p><pre><code>[alias]
  c = commit
</code></pre><p>This file can also be edited direcly to add, remove or updatd aliases for advanced users who are familiar with the correct syntax.</p><h2>Useful Git Aliases</h2><p>Here are a few aliases which I have found improved my own git workflow experience:</p><h3>1. Inline Quick Commit</h3><p>Sometimes you just want to stage and commit all of the files you have modified in the current repository. This command quickly adds the files and commits them:</p><pre><code>git config --global alias.<span class="property">coi</span> <span class="string">"!git add -A &amp;&amp; git commit -m "</span>
</code></pre><p>Which can be run using:</p><pre><code>git coi &lt;commit message&gt;
</code></pre><h3>2. Amend the last commit</h3><p>As developers, we are often optsmistic about our code and have a tendancy to commit our work only to realise we missed a file or forgot to remove a debugging statement. For these occasions, the following alias will ammend the latest commit with all of the changed files in the local repository, without the need to supply a new commit message:</p><pre><code>git config --global alias.<span class="property">coa</span> <span class="string">"!git add -A &amp;&amp; git commit --amend --no-edit"</span>
</code></pre><p>The alias can be run using:</p><pre><code>git coa
</code></pre><h3>3. Push to the remote branch</h3><p>In my git workflow I typically create a branch locally, work on a feature and then want to push my completed work to origin either at the end of the day or once complete (whichever comes first). When I do so for the first time, a branch with the same name does not yet exist on origin so git throws an error. To address this, I use the following alias:</p><pre><code>git config --global alias.<span class="property">po</span> <span class="string">"!git push origin $(git rev-parse --abbrev-ref HEAD)"</span>
</code></pre><p>Which can be run using:</p><pre><code>git po
</code></pre><h3>4. Update Submodules</h3><p>Some of the Git repositories I work with contian one or more nested submodules, to update them I make use of the following alias:</p><pre><code>git config --global alias.<span class="property">usr</span> <span class="string">"!git submodule update --init --recursive"</span>
</code></pre><p>This alias can be run using:</p><pre><code>git usr
</code></pre><h2>Summary</h2><p>We have previously walked through how to setup git hooks that run test suites and now we've demonstrated how easy it is to simplify your git workflow and create aliases for those commands you use frequently or are hard to remember.</p><h2>References</h2><ul><li><a href="https://git-scm.com/book/en/v2/Git-Basics-Git-Aliases "Git Basics - Git Aliases"">Git Basics - Git Aliases</a></li><li><a href="https://mike.gough.me/posts/git-hooks.html "Git pre-commit hook"">Git Hooks</a></li></ul>]]></content:encoded></item><item><guid isPermaLink="true">https://jimlearning.github.io/articles/containerising-bat-test</guid><title>Black-box testing with MuleSoft's Blackbox Automated Testing (BAT) CLI</title><description>In this post we will walk through how you can run a simple test using the BAT CLI inside of a Docker container.</description><link>https://jimlearning.github.io/articles/containerising-bat-test</link><pubDate>Sun, 23 Jun 2019 06:00:00 +0800</pubDate><content:encoded><![CDATA[<h2>Prerequisites</h2><p>To keep things brief, we will assume you already have Docker installed and setup correctly.</p><h2>What is the BAT CLI?</h2><img src="https://jimlearning.github.io/images/posts/mulesoft-logo.svg" alt="MuleSoft logo"/><p>The BAT CLI is an API Functional Monitoring tool produced by MuleSoft for assuring the quality and reliablility of APIs. It provides a convenient method for those working in the MuleSoft technology stack to implement Black-box testing and Runtime monitoring. Using dataweave, it is possible to develop tests that validate the behavior of APIs against live upstream systems, based on inputs and outputs. Additionally, it has a monitoring capability that allows you to verify that deployed APIs are operating as expected and output test results in a variety of formats as a once off operation or on a schedule.</p><h2>Test Writing Language</h2><p>In this post, we will be writing a test manually and running it as a once off operation with the BAT CLI. To begin with, we will need to create file called <code>tests/example.dwl</code> in our working directory. As the <code>dwl</code> file extension indicates, our test will be written using the Dataweave language. Dataweave is an expression language introduced by MuleSoft for transforming data. Within Dataweave, we will use an embeded Domain Specific Language (DSL) called Behaviour Driven Developmenmt (BDD), which has a similar syntax to other testing frameworks, to define our test. The following example shows a typical API test written using BDD in Dataweave, add the example to the <code>tests/example.dwl</code> file:</p><pre><code>%dw <span class="number">2.0</span> <span class="comment">// Dataweave 2.0
// Behaviour Driven Development (BDD) Domain Spesific Langage (DSL)</span>
<span class="keyword">import</span> * from bat::<span class="type">BDD</span> 
<span class="comment">// Common matchers (i.e. mustEqual, mustMatch, every, oneOf, assert, etc.)</span>
<span class="keyword">import</span> * from bat::<span class="type">Assertions</span>
---
<span class="comment">// Defines a suite of related tests</span>
<span class="call">suite</span>(<span class="string">"Example"</span>) <span class="keyword">in</span> [

  <span class="comment">// The result of the test must be 200 to be considered a success</span>
  it must '<span class="keyword">return</span> <span class="number">200</span>' <span class="keyword">in</span> [

    <span class="comment">// Perform a GET request</span>
    <span class="type">GET</span> `$(config.<span class="property">base_url</span>)/zen` <span class="call">with</span> {} assert [
      
      <span class="comment">// Assert that the HTTP response code recieved was 200</span>
      $.<span class="property">response</span>.<span class="property">status</span> mustEqual <span class="number">200</span>
    ] 
  ]
]
</code></pre><p>The <code>$(config.base_url)</code> section from the above example indicates that the test is expecting us to provide the Base URL as a configuration item, rather than hard code it within the test. Building our test in this way gives us the ability to change the Base URL so that our test can be executed against different environments. To store our config, we will need to create a <code>config</code> folder and add some configuration files to it. Lets create a file called <code>config/default.dwl</code> with the following contents:</p><pre><code>%dw <span class="number">2.0</span> <span class="comment">// Dataweave 2.0</span>
---
config::local::<span class="call">main</span>({})
</code></pre><p>Next, create a config file for our production configuration called <code>config/prod.dwl</code> with the following contents:</p><pre><code>%dw <span class="number">2.0</span>
---
{
  base_url: 'https://api.<span class="property">github</span>.<span class="property">com</span>'
}
</code></pre><p>Then, we need to create a manifest file called <code>bat.yaml</code> which will define the tests to be run as well as the type and location of the report to be produced by BAT. The file should have the following contents:</p><pre><code># <span class="type">Name</span> of the test suite
suite:
  name: <span class="string">"Example Test Suite"</span>

# <span class="type">A</span> list of tests to be executed
files:
  - file: ./tests/example.<span class="property">dwl</span>

# <span class="type">A</span> list of reports to be produced
reporters:
  - type: <span class="type">HTML</span>
    outFile: /usr/src/mymaven/results.<span class="property">html</span>
</code></pre><p>Your working directory should now contain the following file structure:</p><pre><code>working-directory
â”œâ”€â”€ bat.<span class="property">yaml</span>
â”œâ”€â”€ tests
â”‚   â””â”€â”€ example.<span class="property">dwl</span>
â””â”€â”€ config
    â”œâ”€â”€ <span class="keyword">default</span>.<span class="property">dwl</span>
    â””â”€â”€ prod.<span class="property">dwl</span>
</code></pre><h2>Validating a Test Suite</h2><p>To validate the files and folders we have created, we can run BAT inside a Docker container and provide some additional command line options. From the base of the working directory, run the following command:</p><pre><code>docker run --<span class="keyword">init</span> --rm \
  -v <span class="string">"${PWD}"</span>:/usr/src/mymaven mikeyryan/mule-blackbox-automated-testing:latest \
  bat.<span class="property">yaml</span> --config=prod --validate
</code></pre><p><code>bat.yaml</code> tells BAT the directory the location of the manifest file. <code>--config=prod</code> selects a configuration file named prod (from the config folder) and registers the result as a global variable for interpolation by our tests</p><h2>Running a Test Suite</h2><p>To execute the tests defined in the manifest file, we can run BAT inside a Docker container using the following command:</p><pre><code>docker run --<span class="keyword">init</span> --rm \
  -v <span class="string">"${PWD}"</span>:/usr/src/mymaven mikeyryan/mule-blackbox-automated-testing:latest \
  bat.<span class="property">yaml</span> --config=prod
</code></pre><p>The output of the command should match the below:</p><pre><code><span class="type">BAT Version</span>: <span class="number">1.0.96</span>
#  <span class="type">File</span>: ./tests/example.<span class="property">dwl</span>
    
    <span class="type">Example</span>
        
        <span class="keyword">return</span> <span class="number">200</span>
          âœ“ <span class="type">GET</span> https://api.<span class="property">github</span>.<span class="property">com</span>/zen (<span class="number">981</span>.18ms)
            âœ“ <span class="number">200</span> must equal <span class="number">200</span>
</code></pre><h2>Summary</h2><p>We have previously walked through how to containerise BAT and now we've demonstrated how easy it is to develop and run BAT tests inside Docker containers.</p><h2>References</h2><ul><li><a href="https://hub.docker.com/r/mikeyryan/mule-blackbox-automated-testing "mikeyryan/mule-blackbox-automated-testing"">Docker Hub - MuleSoft docker images</a></li><li><a href="https://docs.mulesoft.com/api-functional-monitoring/bat-install-task "BAT Installation"">Mulesoft - Install BAT</a></li><li><a href="https://docs.mulesoft.com/api-functional-monitoring/bat-command-reference "BAT CLI Reference"">BAT CLI Reference</a></li><li><a href="https://docs.mulesoft.com/api-functional-monitoring/bat-bdd-reference "BAT BDD Reference"">BAT BDD Reference</a></li></ul>]]></content:encoded></item><item><guid isPermaLink="true">https://jimlearning.github.io/articles/containerising-mule-bat</guid><title>Containerising MuleSoft's Blackbox Automated Testing (BAT) CLI tool</title><description>In this post we will assume that you have Docker and would like to create an image that contains the Blackbox Automated testing (BAT) application published by Mulesoft.</description><link>https://jimlearning.github.io/articles/containerising-mule-bat</link><pubDate>Sat, 22 Jun 2019 10:19:00 +0800</pubDate><content:encoded><![CDATA[<p>If you're looking for a Mule Docker image you can use without making your own, then you can check out <a href="https://hub.docker.com/r/mikeyryan/mule-blackbox-automated-testing">mikeyryan/mule-blackbox-automated-testing</a> on Docker Hub.</p><h2>What is BAT?</h2><img src="https://jimlearning.github.io/images/posts/mulesoft-logo.svg" alt="MuleSoft logo"/><p>The BAT CLI is an API Functional Monitoring tool produced by MuleSoft for assuring the quality and reliablility of APIs. It provides a convenient method for those working in the MuleSoft technology stack to implement Black-box testing and Runtime monitoring. Using dataweave, it is possible to develop tests that validate the behavior of APIs against live upstream systems, based on inputs and outputs. Additionally, it has a monitoring capability that allows you to verify that deployed APIs are operating as expected and output test results in a variety of formats as a once off operation or on a schedule.</p><h2>Why Containerise BAT?</h2><p>BAT will run perfectly fine anywhere that you can install Java. However, you may find yourself in need of a solution that's more scalable than installing it on a standalone machine or needing to run multiple versions it at the same time. In fact, a typical scenario for using BAT is as part of a Continuous Integration (CI) and Continuous Deployment (CD) process to test your API before pushing code into a shared repository and/or verifying that a deployment to production has worked correctly. With Docker we can easily package BAT in a container which is useful for portability, as Docker will help ue sneusre that our tests will run the same locally as they will when deployed to a server or used as part of a CI/CD process.</p><h2>Creating a Docker image</h2><img src="https://jimlearning.github.io/images/posts/docker-logo.svg" alt="Docker logo"/><p>To begin with, we will need to create file called <code>Dockerfile</code> in our working directory. A Dockerfile has a file format that contains instructions and arguments, which define the contents and startup behaviour of the Docker container. To run BAT, our Dockerfile will need to contain the following:</p><pre><code># <span class="type">The</span> first instruction <span class="keyword">in</span> a <span class="type">Dockerfile</span> must be <span class="type">FROM</span>, which selects a base image. <span class="type">Since</span> it's recommended to use official <span class="type">Docker</span> images, we will use the official image <span class="keyword">for</span> maven.
<span class="type">FROM</span> maven:<span class="number">3.6</span>-jdk-<span class="number">8</span>

<span class="type">LABEL</span> maintainer=<span class="string">"https://mike.gough.me"</span>

# <span class="type">Install BAT</span> using the script provided by <span class="type">MuleSoft
RUN</span> curl -o- 'https://s3.<span class="property">amazonaws</span>.<span class="property">com</span>/bat-wrapper/install.<span class="property">sh</span>' | bash

# <span class="type">Set</span> the workdir to the <span class="keyword">default for</span> the maven image we are using
<span class="type">WORKDIR</span> /usr/src/mymaven

# <span class="type">Start BAT</span> when the container <span class="keyword">is</span> run
<span class="type">ENTRYPOINT</span> [<span class="string">"bash"</span>, <span class="string">"bat"</span>]
</code></pre><p>The above Docker file will create an image based on the official maven Docker image. It downloads and installs the latest version of BAT. To create the Docker image with the latest version of BAT, run the following command:</p><pre><code>docker build mule-blackbox-automated-testing:latest .
</code></pre><p>Thats it! In a future post we will look at how we can use our BAT container to test an API.</p><h2>References</h2><ul><li><a href="https://hub.docker.com/r/mikeyryan/mule-blackbox-automated-testing "mikeyryan/mule-blackbox-automated-testing"">Docker Hub - MuleSoft docker images</a></li><li><a href="https://docs.mulesoft.com/api-functional-monitoring/bat-install-task "BAT Installation"">Mulesoft - Install BAT</a></li><li><a href="https://github.com/Mike-Gough/mule-blackbox-automated-testing "BAT Dockerfile source code"">GitHub - Source code</a></li></ul>]]></content:encoded></item><item><guid isPermaLink="true">https://jimlearning.github.io/articles/linux-subsystem-for-windows</guid><title>Setup Subsystem for Linux on Windows 10</title><description>Windows Subsystem for Linux (WSL) lets developers run GNU/Linux code side-by-side with Windows processes. In this post we will walk through how you can setup WSL.</description><link>https://jimlearning.github.io/articles/linux-subsystem-for-windows</link><pubDate>Sat, 8 Jun 2019 14:20:00 +0800</pubDate><content:encoded><![CDATA[<h2>Prerequisites</h2><p>To keep things simple, we will assume you have the following:</p><ul><li>A Windows 10 Machine with build 16215 or later</li><li>An administrator account</li><li>A Windows Store account</li></ul><h2>What is WSL?</h2><p>WSL is an optional feature of Windows 10 that allows Linux programs to run nativly on Windows. It was originally desiged by Microsoft in partnetship with Canonical (the creators of Ubuntu) and provides an environment that looks and behaves just like Linux. At a high level this allows you to run Linux code without having to fire up a Virtual Machine.</p><h2>Why WSL?</h2><p>WSL gives Windows users access to powerful Linux applications and GNU tools such as find, awk, sed and grep. Although not all Linux applications can be used, it comes with software package tools such as apt and dpkg which can be used to install applications. WSL shows its utility in Continuous Integration and Continuous Delivery environmens that make use of open source software, as many open source tools and libraries assume developers are using Linux. While tools such as Docker help to ensure developed applications can be run consistently, WSL helps to ensure they can be developed consistently.</p><h2>Enable WSL</h2><p>Begin by opening PowerShell as an Administrator and running the following command:</p><pre><code><span class="type">Enable</span>-<span class="type">WindowsOptionalFeature</span> -<span class="type">Online</span> -<span class="type">FeatureName Microsoft</span>-<span class="type">Windows</span>-<span class="type">Subsystem</span>-<span class="type">Linux</span>
</code></pre><p>Then restart your computer if prompted.</p><h2>Install your Linux Distribution of Choice</h2><p>To download and install your preferred distribution of linux, open the Windows Store and search for <code>WSL</code> or click on one of the links below:</p><ul><li><a href="https://www.microsoft.com/store/p/ubuntu/9nblggh4msv6">Ubuntu</a></li><li><a href="https://www.microsoft.com/store/apps/9njvjts82tjx">OpenSUSE</a></li><li><a href="https://www.microsoft.com/store/apps/9p32mwbh6cns">SLES</a></li><li><a href="https://www.microsoft.com/store/apps/9PKR34TNCV07">Kali Linux</a></li><li><a href="https://www.microsoft.com/store/apps/9MSVKQC78PK6">Debian GNU/Linux</a></li></ul><p>On the distributions page, click the <em>Get</em> button. After pressing get, you may find you need to hit an <em>Install</em> button. Once your Linux distribution is installed, you must initialize it before it can be used.</p><h2>Initialising a new Linux Distribution</h2><p>To complete the initialisation of your newly installed distribution,you'll need to launch an instance of it. You can do this by clicking the <em>Launch</em> button inside the Windows Store, or by launching it from the Start menu. The first time a newly installed distribution launches, a Console window will open and you'll be asked to wait for the installation to complete.</p><p>Once the distributions files are de-compressed and stored on your PC, you'll be prompted to setup a new Linux user account. When prompted, enter a new UNIX username and password. The user account that will created is a normal (non-administrator) user that you'll be logged-in as by default when launching the discribution. Make sure to chose a password you will remember, as when elevating your prilidges (using sudo), you will need to enter your password.</p><h2>Updating and upgrading your distributons packages</h2><p>Most distributions ship with an minimal packages to keep the initial download size small. Microsoft recommend regularly updating your package catalog, and upgrading your installed packages using the distributions preferred package manager:</p><ul><li>On Debian/Ubuntu, you use apt: <code>sudo apt update &amp;&amp; sudo apt upgrade</code></li><li>On OpenSuse, you use zypper: <code>sudo zypper refresh &amp;&amp; sudo zypper update</code></li></ul><h2>Summary</h2><p>We have walked through how to enable WSL, install a Linux Distribution and ensure it is up to date. You should now have a working Linux Distribution on your Windows 10 Machine that you can use to run bash scrips and much more.</p><h2>References</h2><ul><li><a href="https://docs.microsoft.com/en-us/windows/wsl/about "About the Windows Subsystem for Linux"">About the Windows Subsystem for Linux</a></li><li><a href="https://docs.microsoft.com/en-us/windows/wsl/install-win10 "Install on Windows 10"">Install on Windows 10</a></li><li><a href="https://docs.microsoft.com/en-us/windows/wsl/initialize-distro "Initialize distro"">Initialize distro</a></li></ul>]]></content:encoded></item><item><guid isPermaLink="true">https://jimlearning.github.io/articles/kubernetes-dashboard-deployment</guid><title>Using Kubernetes dashboard to deploy a Mule 4 application</title><description>Once you have a running Kubernetes cluster, you can deploy your containerised applications on top of it. In this post we will walk through how you can deploy a containerised mule application using the Kubernetes dashboard.</description><link>https://jimlearning.github.io/articles/kubernetes-dashboard-deployment</link><pubDate>Thu, 30 May 2019 06:10:00 +0800</pubDate><content:encoded><![CDATA[<h2>Prerequisites</h2><p>To keep things simple, we will assume you have already setup a local single node Kubernetes cluster and deployed its dashboard.</p><h2>Create a new Kubernetes deployment</h2><img src="https://jimlearning.github.io/images/posts/kubernetes-logo.svg" alt="Kubernetes logo"/><p>Begin by using your browser to navigate to the Kubernetes dashboard running on your local machine <a href="http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/">http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/</a>. Use the menu to the left of the page to open the <em>Deployments</em> screen:</p><img src="https://jimlearning.github.io/images/posts/kubernetes-deployments.jpg" alt="Deployments screen"/><p>Then click the <em>Create</em> button in the top right hand corner. In the Wizard that appears, select the <em>Create an App</em> tab and provide the following values:</p><ul><li>app name: mule-4-hello-world</li><li>container image: mikeyryan/mule-4-hello-world:ce</li><li>number of pods: 1</li><li>service: External</li><li>port: 8081</li><li>target port: 8081</li><li>protocol: TCP</li></ul><p>If you've been following on from earlier walkthroughs, or have your own containerised Mule application, feel free to replace the value for the container image. The image <code>mikeyryan/mule-4-hello-world:ce</code> is a a simple Hello World application for Mule 4. It has a single HTTP listener flow that listens on <code>http://localhost:8081/api/hello-world</code> and can be found on <a href="https://github.com/Mike-Gough/mule-4-hello-world">GitHub</a>.</p><img src="https://jimlearning.github.io/images/posts/kubernetes-deployment-create-an-app.jpg" alt="Create an app"/><p>Finally, click the <em>Deploy</em> button. Once the deployment starts we can see the deployment name in the Dashboard on the Deployments screen:</p><img src="https://jimlearning.github.io/images/posts/kubernetes-deployments-with-mule-4-hello-world.jpg" alt="Deployments deployment screen with a mule app"/><p>To verify that the application has started successfully, you can use the menu to the left of the page to open the <em>Pods</em> screen:</p><img src="https://jimlearning.github.io/images/posts/kubernetes-pods.jpg" alt="Kubernetes pods screen with a mule pod"/><p>And click the circled icon to inspect the logs for the running mule-4-hello-world Docker container. You should see a screen similar to this:</p><img src="https://jimlearning.github.io/images/posts/kubernetes-pods-log.jpg" alt="Kubernetes pods screen with the logs for a mule pod"/><h2>Testing the application</h2><p>Now that we have verified that the application has been deployed successfully, we are ready to test it. The containerised <code>mule-4-hello-world</code> application exposes an API endpoint on port 8081. When deploying the example using Kubernetes we chose to leave the port the same, but make it externally accessible. As such the application can be accessed by navigating to <a href="http://localhost:8081/api/hello-world">http://localhost:8081/api/hello-world</a> in your browser. When accessed, your browser should show:</p><pre><code><span class="type">Hello</span> from <span class="type">Mule</span> <span class="number">4.2.0</span>
</code></pre><h2>Summary</h2><p>We have previously walked through how to containerise the Mule ESB as well as a Mule 4 application. Now we've demonstrated how easy it is deploy a containerised Mule 4 application using the Kubernetes dashboard. In future posts we will look at how this can be achieved using Kubectl.</p><h2>References</h2><ul><li><a href="https://kubernetes.io/docs/tutorials/kubernetes-basics/ "Kubernetes Basics"">Kubernetes Basics</a></li></ul>]]></content:encoded></item><item><guid isPermaLink="true">https://jimlearning.github.io/articles/containerising-mule-esb-applications</guid><title>Containerising a Mule 4 application</title><description>In this post we will walk through how you can run a simple Mule 4 application inside of a Docker container.</description><link>https://jimlearning.github.io/articles/containerising-mule-esb-applications</link><pubDate>Tue, 28 May 2019 13:29:00 +0800</pubDate><content:encoded><![CDATA[<h2>Prerequisites</h2><p>To keep things brief, we will assume you already have JDK 8, Maven 3 and Docker installed and setup correctly. Your docker host needs to have at least 1GB of available RAM to run Mule ESB Server Runtime. You can refer to the <a href="https://docs.mulesoft.com/mule-runtime/4.2/hardware-and-software-requirements">Mule ESB hardware requirements</a> documentation for additional information.</p><h2>Hello world Mule 4 application</h2><img src="https://jimlearning.github.io/images/posts/mulesoft-logo.svg" alt="MuleSoft logo"/><p>I have created a simple Hello World application inside Mule 4 which can be used for this walkthrough. It has a single HTTP listener flow that listens on <code>http://localhost:8081/api/hello-world</code> and can be found on <a href="https://github.com/Mike-Gough/mule-4-hello-world">GitHub</a>. The GitHub repository contains an example for both the community edition and enterprise edition of Mule. You can download and use either example, or if you prefer, your own application. However, if you choose to use the enterprise edition inside Docker you may need to install a licence file.</p><h2>Building the application</h2><p>To build the application, open your Command Line Interface (CLI) of choice, navigate to the application directory and run:</p><pre><code>mvn clean package
</code></pre><p>This will cause Maven to create a <code>target</code> folder and package the application into a jar file inside of it. We will be using this jar file inside of our Docker image.</p><h2>Creating a Docker image for the Mule application</h2><p>To begin with, we will need to create a new file called <code>Dockerfile</code> in our working directory. A Dockerfile has a file format that contains instructions and arguments, which define the contents and startup behaviour of the Docker container. To containerise the example Mule application, our Dockerfile will need to have the following contents for a community edition application:</p><pre><code># <span class="type">The</span> first instruction <span class="keyword">in</span> a <span class="type">Dockerfile</span> must be <span class="type">FROM</span>, which selects a base image. <span class="type">We</span> are using the image <span class="type">I</span> published from a previous post about containerising the <span class="type">Mule ESB</span>. <span class="type">Change</span> this line to your own repository <span class="keyword">if</span> you have created your own image.
<span class="type">FROM</span> mikeyryan/mule:<span class="number">4.2.0</span>-ce

# <span class="type">Copy</span> the jar that was generated during the package maven phase and place it <span class="keyword">in</span> the apps folder
<span class="type">COPY</span> ./target/mule-<span class="number">4</span>-hello-world*.jar /opt/mule/apps/

# <span class="type">Start</span> the mule runtime
<span class="type">CMD</span> [<span class="string">"/opt/mule/bin/mule"</span>]

# <span class="type">HTTP</span> listener <span class="keyword">default</span> port
<span class="type">EXPOSE</span> <span class="number">8081</span>
</code></pre><p>If you are containerising an enterprise edition application, you will need to replace <code>-ce</code> with <code>-ee</code> in the line that begins with FROM. For applications other than the provided example from GitHub, you will need to modify the name of the JAR inside the COPY command to match the name of your project.</p><p>The above Dockerfile builds an image based on a pre-existing Mule ESB image and adds the application to it. Run it now by executing the following command:</p><pre><code>docker build \
  --tag mule-<span class="number">4</span>-hello-world .
</code></pre><p>This command creates a Docker image called <code>mule-4-hello-world</code> which we can use to run our application.</p><h2>Running the application using Docker</h2><p>To start a Docker container based on this image, execute the following command:</p><pre><code>docker run --rm -it \
  --name mule-<span class="number">4</span>-hello-world \
  -p <span class="number">8081</span>:<span class="number">8081</span> \
  mule-<span class="number">4</span>-hello-world
</code></pre><p>This will start a Docker container which will run in the foreground. The Docker image exposes port 8081 and binds it to the same port on localhost.</p><p>Once the application is running, it can be accessed by navigating to <a href="http://localhost:8081/api/hello-world">http://localhost:8081/api/hello-world</a> in your browser. When accessed, your browser should show:</p><pre><code><span class="type">Hello</span> from <span class="type">Mule</span> <span class="number">4.2.0</span>
</code></pre><h2>Summary</h2><p>We have previously walked through how to containerise the Mule ESB and now we've demonstrated how easy it is to run Mule applications inside Docker containers. For those who prefer not to venture down the path of containerising the Mule ESB themselves, they can still containerise a Mule application using the mikeyryan/mule image to easily get up and running.</p><h2>References</h2><ul><li><a href="https://mike.gough.me/posts/docker/mule/esb/enterprise-edition "Containerising Mule Enterprise Service Bus (ESB) Enterprise Edition"">Containerising Mule Enterprise Service Bus (ESB) Enterprise Edition</a></li><li><a href="https://mike.gough.me/posts/docker/mule/esb/community-edition "Containerising Mule Enterprise Service Bus (ESB) Community Edition"">Containerising Mule Enterprise Service Bus (ESB) Community Edition</a></li><li><a href="https://github.com/Mike-Gough/mule-4-hello-world "Mike-Gough/mule-4-hello-world"">Mule 4 - Example hello world application repository</a></li></ul>]]></content:encoded></item><item><guid isPermaLink="true">https://jimlearning.github.io/articles/containerising-mule-esb-enterprise-edition</guid><title>Containerising Mule Enterprise Service Bus (ESB) Enterprise Edition</title><description>In this post we will assume that you have Docker and would like to create an image that contains the Enterprise Edition of the Mule ESB.</description><link>https://jimlearning.github.io/articles/containerising-mule-esb-enterprise-edition</link><pubDate>Mon, 27 May 2019 11:40:00 +0800</pubDate><content:encoded><![CDATA[<p>If you're looking for a Mule Docker image you can use without making your own, then you can check out <a href="https://hub.docker.com/r/mikeyryan/mule">mikeyryan/mule</a> on Docker Hub.</p><h2>Why Containerise the Mule ESB?</h2><img src="https://jimlearning.github.io/images/posts/mulesoft-logo.svg" alt="MuleSoft logo"/><p>The Mule ESB will run perfectly fine anywhere that you can install Java. However, you may find yourself in need of a solution that's more scalable than installing it on a standalone machine. A typical scenario for using the Mule ESB is to install it on a standalone server and then deploy all of your applications to it. This comes with a few disadvantages, primarily that a single unhealthy app can impact others in the same Mule ESB. One method of addressing this is to run multiple versions of the Mule ESB on the server, which is where Docker comes in.</p><p>With Docker we can easily deploy containers with the Mule ESB and a single application that will run in an independent isolated environment. This can also be useful for portability, as Docker will help us ensure that the application will run the same locally as it would when it's deployed to a server or the cloud.</p><h2>Creating a Docker image</h2><img src="https://jimlearning.github.io/images/posts/docker-logo.svg" alt="Docker logo"/><p>To begin with, we will need to create a new file called <code>Dockerfile</code> in our working directory. A Dockerfile has a file format that contains instructions and arguments, which define the contents and startup behaviour of the Docker container. To run the Mule ESB, our Dockerfile will need to contain the following:</p><pre><code># <span class="type">The</span> first instruction <span class="keyword">in</span> a <span class="type">Dockerfile</span> must be <span class="type">FROM</span>, which selects a base image. <span class="type">Since</span> it's recommended to use official <span class="type">Docker</span> images, we will use the official image <span class="keyword">for</span> openjdk.
<span class="type">FROM</span> openjdk:<span class="number">8</span>-jdk

<span class="type">LABEL</span> maintainer=<span class="string">"https://mike.gough.me"</span>

# <span class="type">Define</span> environment variables <span class="keyword">as</span> arguments that can be passed <span class="keyword">in</span> when building this image.
<span class="type">ARG MULE_VERSION</span>=<span class="number">4.2.0</span>
<span class="type">ARG MULE_MD5</span>=0f098b4bbc65d27cee9af59904ed6545
<span class="type">ARG TZ</span>=<span class="type">Australia</span>/<span class="type">Sydney

ENV MULE_HOME</span>=/opt/mule
<span class="type">ENV MULE_DOWNLOAD_URL</span> http://s3.<span class="property">amazonaws</span>.<span class="property">com</span>/new-mule-artifacts/mule-ee-distribution-standalone-${<span class="type">MULE_VERSION</span>}.zip

# <span class="type">Set</span> the timezone
<span class="type">RUN</span> echo ${<span class="type">TZ</span>} &gt; /etc/timezone

# <span class="type">Set</span> the working directory
<span class="type">WORKDIR</span> ${<span class="type">MULE_HOME</span>}

<span class="type">RUN</span> mkdir -p /opt &amp;&amp; \
    cd /opt &amp;&amp; \
    wget <span class="string">"$MULE_DOWNLOAD_URL"</span> -<span class="type">O</span> mule-ee-distribution-standalone-${<span class="type">MULE_VERSION</span>}.zip

# <span class="type">Unpack Mule ESB
RUN</span> cd /opt &amp;&amp; \
  rm -rf mule-enterprise-standalone-${<span class="type">MULE_VERSION</span>} &amp;&amp; \
  unzip mule-ee-distribution-standalone-${<span class="type">MULE_VERSION</span>}.zip &amp;&amp; \
  rm -rf mule-standalone-${<span class="type">MULE_VERSION</span>} &amp;&amp; \
  rm -f mule-ee-distribution-standalone-${<span class="type">MULE_VERSION</span>}.zip &amp;&amp; \
  mv mule-enterprise-standalone-${<span class="type">MULE_VERSION</span>} mule-standalone-${<span class="type">MULE_VERSION</span>}

<span class="type">RUN</span> cd /opt &amp;&amp; \
  rm -rf mule &amp;&amp; \
  ln -s mule-standalone-${<span class="type">MULE_VERSION</span>} mule

# <span class="type">Set</span> the mount locations
<span class="type">VOLUME</span> [<span class="string">"${MULE_HOME}/logs"</span>, <span class="string">"${MULE_HOME}/conf"</span>, <span class="string">"${MULE_HOME}/apps"</span>, <span class="string">"${MULE_HOME}/domains"</span>, <span class="string">"${MULE_HOME}/patches"</span>, <span class="string">"${MULE_HOME}/.mule"</span>]

# <span class="type">Run</span> this command on container start
<span class="type">CMD</span> [ <span class="string">"${MULE_HOME}/bin/mule"</span>]

# <span class="type">HTTP</span> listener <span class="keyword">default</span> port, remote debugger, <span class="type">JMX</span>, <span class="type">MMC</span> agent, <span class="type">AMC</span> agent
<span class="type">EXPOSE</span> <span class="number">8081 5000 1098 7777 9997</span>
</code></pre><p>The above Docker file will create an image based on the official openjdk Docker image. It downloads and installs a specific version of the Mule ESB which can be passed as an optional argument when running the build process. To create the Docker image with version 4.2.0 of the Mule ESB, run the following command:</p><pre><code>docker build \
  --build-arg <span class="type">MULE_VERSION</span>=<span class="number">4.2.0</span> \
  -t mule:ee-<span class="number">4</span>-<span class="number">2</span>-<span class="number">0</span> .
</code></pre><p>With newer versions of Mule (4 and above) you may need to provide a licence instead of using a 30 day trial.</p><p>Thats it! In a future post we will look at how we can use this image as the base for another image which contains a Mule application.</p><h2>References</h2><ul><li><a href="https://hub.docker.com/r/mikeyryan/mule "mikeyryan/mule"">Docker Hub - Mule docker images</a></li><li><a href="https://docs.mulesoft.com/mule-runtime/4.2/mule-standalone "Mule Installation"">Mule Installation</a></li><li><a href="https://www.mulesoft.com/lp/dl/mule-esb-enterprise "Mule 4 standalone"">Mule 4 Standalone</a></li></ul>]]></content:encoded></item><item><guid isPermaLink="true">https://jimlearning.github.io/articles/containerising-mule-esb-community-edition</guid><title>Containerising Mule Enterprise Service Bus (ESB) Community Edition</title><description>In this post we will assume that you have Docker and would like to create an image that contains the Community Edition of the Mule ESB.</description><link>https://jimlearning.github.io/articles/containerising-mule-esb-community-edition</link><pubDate>Sun, 26 May 2019 08:35:00 +0800</pubDate><content:encoded><![CDATA[<p>If you're looking for a Mule Docker image you can use without making your own, then you can check out <a href="https://hub.docker.com/r/mikeyryan/mule">mikeyryan/mule</a> on Docker Hub.</p><h2>Why Containerise the Mule ESB?</h2><img src="https://jimlearning.github.io/images/posts/mulesoft-logo.svg" alt="MuleSoft logo"/><p>The Mule ESB will run perfectly fine anywhere that you can install Java. However, you may find yourself in need of a solution that's more scalable than installing it on a standalone machine. A typical scenario for using the Mule ESB is to install it on a standalone server and then deploy all of your applications to it. This comes with a few disadvantages, primarily that a single unhealthy app can impact others in the same Mule ESB. One method of addressing this is to run multiple versions of the Mule ESB on the server, which is where Docker comes in.</p><p>With Docker we can easily deploy containers with the Mule ESB and a single application that will run in an independent isolated environment. This can also be useful for portability, as Docker will help us ensure that the application will run the same locally as it would when it's deployed to a server or the cloud.</p><h2>Creating a Docker image</h2><img src="https://jimlearning.github.io/images/posts/docker-logo.svg" alt="Docker logo"/><p>To begin with, we will need to create file called <code>Dockerfile</code> in our working directory. A Dockerfile has a file format that contains instructions and arguments, which define the contents and startup behaviour of the Docker container. To run the Mule ESB, our Dockerfile will need to contain the following:</p><pre><code># <span class="type">The</span> first instruction <span class="keyword">in</span> a <span class="type">Dockerfile</span> must be <span class="type">FROM</span>, which selects a base image. <span class="type">Since</span> it's recommended to use official <span class="type">Docker</span> images, we will use the official image <span class="keyword">for</span> openjdk.
<span class="type">FROM</span> openjdk:<span class="number">8</span>-jdk

<span class="type">LABEL</span> maintainer=<span class="string">"https://mike.gough.me"</span>

# <span class="type">Define</span> environment variables <span class="keyword">as</span> arguments that can be passed <span class="keyword">in</span> when building this image.
<span class="type">ARG MULE_VERSION</span>=<span class="number">4.2.0</span>
<span class="type">ARG TZ</span>=<span class="type">Australia</span>/<span class="type">Sydney

ENV MULE_HOME</span>=/opt/mule
<span class="type">ENV MULE_DOWNLOAD_URL</span> https://repository-master.<span class="property">mulesoft</span>.<span class="property">org</span>/nexus/content/repositories/releases/org/mule/distributions/mule-standalone/${<span class="type">MULE_VERSION</span>}/mule-standalone-${<span class="type">MULE_VERSION</span>}.tar.<span class="property">gz</span>

# <span class="type">Set</span> the timezone
<span class="type">RUN</span> echo ${<span class="type">TZ</span>} &gt; /etc/timezone

# <span class="type">Set</span> the working directory
<span class="type">WORKDIR</span> ${<span class="type">MULE_HOME</span>}

<span class="type">RUN</span> mkdir -p /opt &amp;&amp; \
    cd /opt &amp;&amp; \
    wget <span class="string">"$MULE_DOWNLOAD_URL"</span> -<span class="type">O</span> mule-standalone-${<span class="type">MULE_VERSION</span>}.tar.<span class="property">gz</span>

# <span class="type">Unpack Mule ESB
RUN</span> tar xvzf /opt/mule-standalone-${<span class="type">MULE_VERSION</span>}.tar.<span class="property">gz</span> -<span class="type">C</span> /opt &amp;&amp; \
  rm -f /opt/mule-standalone-${<span class="type">MULE_VERSION</span>}.tar.<span class="property">gz</span>

<span class="type">RUN</span> cd /opt &amp;&amp; \
  rm -rf mule &amp;&amp; \
  ln -s mule-standalone-${<span class="type">MULE_VERSION</span>} mule

# <span class="type">Set</span> the mount locations
<span class="type">VOLUME</span> [<span class="string">"${MULE_HOME}/logs"</span>, <span class="string">"${MULE_HOME}/conf"</span>, <span class="string">"${MULE_HOME}/apps"</span>, <span class="string">"${MULE_HOME}/domains"</span>, <span class="string">"${MULE_HOME}/patches"</span>, <span class="string">"${MULE_HOME}/.mule"</span>]

# <span class="type">Run</span> this command on container start
<span class="type">CMD</span> [ <span class="string">"${MULE_HOME}/bin/mule"</span>]

# <span class="type">HTTP</span> listener <span class="keyword">default</span> port, remote debugger, <span class="type">JMX</span>, <span class="type">MMC</span> agent, <span class="type">AMC</span> agent
<span class="type">EXPOSE</span> <span class="number">8081 5000 1098 7777 9997</span>
</code></pre><p>The above Docker file will create an image based on the official openjdk Docker image. It downloads and installs a specific version of the Mule ESB which can be passed as an optional argument when running the build process. To create the Docker image with version 4.2.0 of the Mule ESB, run the following command:</p><pre><code>docker build \
  --build-arg <span class="type">MULE_VERSION</span>=<span class="number">4.2.0</span> \
  -t mule:ce-<span class="number">4</span>-<span class="number">2</span>-<span class="number">0</span> .
</code></pre><p>Thats it! In a future post we will look at how we can use this image as the base for another image which contains a Mule application.</p><h2>References</h2><ul><li><a href="https://hub.docker.com/r/mikeyryan/mule "mikeyryan/mule"">Docker Hub - Mule docker images</a></li><li><a href="https://docs.mulesoft.com/mule-runtime/4.2/mule-standalone "Mule Installation"">Mule Installation</a></li><li><a href="https://developer.mulesoft.com/download-mule-esb-runtime "Mule Kernel"">Mule Kernel</a></li></ul>]]></content:encoded></item><item><guid isPermaLink="true">https://jimlearning.github.io/articles/github-actions</guid><title>Continuous Deployment with GitHub Actions and Docker Hub</title><description>In this post we will assume that you practice Continuous Integration (CI) and have a product which is packaged as a Docker image. As your next step you are looking to implement Continuous Deployment (CD) from scratch or move to it from a Continuous Delivery workflow. Our aim will be to build and push a docker image to Docker Hub using GitHub actions.</description><link>https://jimlearning.github.io/articles/github-actions</link><pubDate>Mon, 20 May 2019 16:25:00 +0800</pubDate><content:encoded><![CDATA[<h2>Principles</h2><p>Before we dive into how we can achieve this goal, itâ€™s important to understand the principles behind what we are trying to achieve and why. If youâ€™re already familiar with Continuous Delivery and Continuous Deployment as well as the distinction between the two, feel free to skip this next part.</p><h3>What is Continuous Delivery?</h3><p>Continuous Delivery is a software development discipline where you build software in such a way that the it can be released to production at any time<sup>[1]</sup>. In a Continuous Delivery workflow, each development change that is pushed to the main repository is ready to be shipped. However, the action of shipping requires human approval. Although there is usually a focus on automated testing as part of this process, in many organisations the risk of promoting a release to production is shouldered by the individual approving that release. Onus is placed on the developers to prioritise keeping the code deliverable over implementing new features.</p><h3>How does Continuous Delivery differ from Continuous Deployment?</h3><p>By contrast, in Continuous Deployment each development change that is pushed to the main repository is automatically released to production, without any human intervention. In this workflow, a strong emphasis is placed on automated testing, as it should not be possible to merge code into the main development branch without that code passing a test suite. This means that the quality of your test suite determines the level of risk for a release, and automated testing must be prioritised during development. As such itâ€™s important to ensure you donâ€™t fall into the trap of mistaking good code coverage in your test suite for good quality tests. Developers within the team must ensure that the quality of tests presented in code reviews remains high.</p><h2>Using Github actions for Continuous Deployment</h2><p>Now that we understand what Continuous Deployment is and what we are aiming for, letâ€™s create a workflow that builds a Docker image and publishes it to Docker Hub. To begin, youâ€™ll need to navigate to GitHub, ensure you are logged in and have opened the repository that you would like to work with. The repository should already contain a <code>Dockerfile</code>. Click the <em>Actions</em> button at the top of the page: <img src="https://jimlearning.github.io/images/posts/github-actions-title-bar.jpg" alt="GitHub actions button"/></p><p>GitHub will prompt you to confirm that youâ€™d like to create a new workflow, click the <em>Create a new workflow</em> button: <img src="https://jimlearning.github.io/images/posts/github-actions-create-button.jpg" alt="Git hook screenshot"/></p><p>Leave the name of the file as <code>main.workflow</code> and click the button labelled <em>Edit file</em> <img src="https://jimlearning.github.io/images/posts/github-actions-heading.jpg" alt="Git hook screenshot"/></p><p>Add the following to the contents of the editor, replacing <code>&lt;project-name&gt;</code> and <code>&lt;docker-hub-username&gt;</code> with the name of your project and username for Docker Hub:</p><pre><code># <span class="type">Create</span> a new workflow thatâ€™s triggered by a push to master
workflow <span class="string">"Build on push"</span> {
  on = <span class="string">"push"</span>
  resolves = [
    <span class="string">"Push Docker image with build number"</span>,
    <span class="string">"Push Docker image with latest"</span>,
    <span class="string">"Archive release"</span>
  ]
}

# <span class="type">Optionally</span> add an action to run your test suite here

# <span class="type">Filter</span> pushes to only those on the master branch
action <span class="string">"Filter for master"</span> {
  uses = <span class="string">"actions/bin/filter@master"</span>
  args = <span class="string">"branch master"</span>
}

# <span class="type">Login</span> to <span class="type">Docker Hub</span> with your credentials (<span class="type">The GitHub UI</span> will prompt you <span class="keyword">for</span> them <span class="keyword">if</span> they have not already been provided).
action <span class="string">"Authenticate with Docker Registry"</span> {
  uses = <span class="string">"actions/docker/login@master"</span>
  needs = [<span class="string">"Filter for master"</span>]
  secrets = [<span class="string">"DOCKER_USERNAME"</span>, <span class="string">"DOCKER_PASSWORD"</span>]
}

# <span class="type">Build</span> a docker image based off of a <span class="type">Dockerfile</span> <span class="keyword">in</span> the root directory of the repository
action <span class="string">"Build Docker Image"</span> {
  uses = <span class="string">"actions/docker/cli@8cdf801b322af5f369e00d85e9cf3a7122f49108"</span>
  needs = [<span class="string">"Authenticate with Docker Registry"</span>]
  args = <span class="string">"build -f Dockerfile --tag &lt;project-name&gt; ."</span>
}

# <span class="type">Give</span> the docket image a unique tag based on the <span class="type">GitHub SHA</span>
action <span class="string">"Tag Docker Image with build number"</span> {
  uses = <span class="string">"actions/docker/cli@8cdf801b322af5f369e00d85e9cf3a7122f49108"</span>
  needs = [<span class="string">"Build Docker Image"</span>]
  args = <span class="string">"tag &lt;project-name&gt; &lt;docker-hub-username&gt;/&lt;project-name&gt;:$GITHUB_SHA"</span>
}

# <span class="type">Automatically</span> push the image to <span class="type">Docker Hub</span>
action <span class="string">"Push Docker image with build number"</span> {
  uses = <span class="string">"actions/docker/cli@8cdf801b322af5f369e00d85e9cf3a7122f49108"</span>
  needs = [<span class="string">"Tag Docker Image with build number"</span>]
  args = <span class="string">"push &lt;docker-hub-username&gt;/&lt;project-name&gt;:$GITHUB_SHA"</span>
}

# <span class="type">Filter</span> <span class="keyword">for</span> a tag which indicates that this push <span class="keyword">is</span> a release (i.<span class="property">e</span>. <span class="property">the</span> push <span class="keyword">is</span> tagged with v1.<span class="number">0.0</span>)
action <span class="string">"Filter for tag"</span> {
  uses = <span class="string">"actions/bin/filter@master"</span>
  needs = [<span class="string">"Push Docker image with build number"</span>]
  args = <span class="string">"tag v*"</span>
}

# <span class="type">Tag</span> the docket image <span class="keyword">as</span> latest
action <span class="string">"Tag Docker Image with latest"</span> {
  uses = <span class="string">"actions/docker/cli@8cdf801b322af5f369e00d85e9cf3a7122f49108"</span>
  needs = [<span class="string">"Filter for tag"</span>]
  args = <span class="string">"tag &lt;project-name&gt; &lt;docker-hub-username&gt;/&lt;project-name&gt;:latest"</span>
}

# <span class="type">Automatically</span> push the image tagged latest to <span class="type">Docker Hub</span>
action <span class="string">"Push Docker image with latest"</span> {
  uses = <span class="string">"actions/docker/cli@8cdf801b322af5f369e00d85e9cf3a7122f49108"</span>
  needs = [<span class="string">"Tag Docker Image with latest"</span>]
  args = <span class="string">"push &lt;docker-hub-username&gt;/&lt;project-name&gt;:latest"</span>
}

# <span class="type">Create</span> a release <span class="type">ZIP</span> archive and add it to the repository
action <span class="string">"Archive release"</span> {
  uses = <span class="string">"lubusIN/actions/archive@master"</span>
  needs = [<span class="string">"Filter for tag"</span>]
  env = {
    <span class="type">ZIP_FILENAME</span> = <span class="string">"&lt;project-name&gt;"</span>
  }
}
</code></pre><p>That was a lot to digest, so letâ€™s take a look at the actions in this workflow. The workflow is trigged by any push to the repository. The first action filters out all pushes other than those to the master branch. It then attempts to login to Docker Hub using the credentials you have supplied as secrets.</p><p>Once authenticated, an action builds a Docker image, another tags it and yet another pushes it to Docker Hub. The next action is a filter, it checks if the push to the master branch was tagged as a release. If the push was a release then the next action tags the Docker image as latest and another pushes it to Docker Hub. Finally, an action zips the source code up and publishes it to the release page on GitHub.</p><p>To see all of this in action, commit the <code>main.workflow</code> file to the repository. Navigating to the actions tab should now show any in-progress builds as well as historical ones:</p><img src="https://jimlearning.github.io/images/posts/github-actions-run-results.jpg" alt="Git hook screenshot"/><h2>References</h2><ul><li><a href="https://martinfowler.com/bliki/ContinuousDelivery.html        "Martin Fowler - Continuous Delivery"">Martin Fowler - Continuous Delivery</a></li></ul>]]></content:encoded></item><item><guid isPermaLink="true">https://jimlearning.github.io/articles/git-hooks</guid><title>Git pre-commit hook for Linting RESTful API Modelling Language (RAML)</title><description>Continuous Integration (CI) is a practice that requires developers to push code into a shared repository several times a day. When pushing our code to a shared repository, we should strive to ensure that our code is syntactically correct and builds so that other developers can grab the latest copy and begin iterating upon it easily. Today we are going to look at this principle and how we can easily identify and correct common coding mistakes when designing Service Contracts for Application Programming Interfaces (APIs). Specifically, we will explore how we can use Git hooks as a mechanism for ensuring a RAML Service Contract is valid using a Linter called RAML Enforcer.</description><link>https://jimlearning.github.io/articles/git-hooks</link><pubDate>Sat, 18 May 2019 09:45:00 +0800</pubDate><content:encoded><![CDATA[<h2>What is RAML Enforcer?</h2><p><em>RAML Enforcer</em> is a Linter which can be used to examine source code for programatic errors, bugs, stylistic errors or suspicious patterns. In a CI toolchain, <em>Linting</em> is performed very early in the workflow, usually prior to running unit tests or integrating code into a shared repository. <em>RAML Enforcer</em> is configurable through command line arguments and provides developers with the option to select from a set of prepackaged rules to enforce coding standards. In this case, we are interested in automatically checking our Service Contract for programatic errors and bugs prior to committing any changes.</p><h2>How can RAML Enforcer be run automatically?</h2><p>Git has a mechanism for triggering scripts when interesting events occur, called hooks. There are two main categories of hooks, client side and server side. To address our goal of checking the quality of our RAML before integrating it into our local version control repository, we will look at using a local pre-commit hook. So.. what is a pre-commit hook, you ask? A pre-commit hook is a script that Git executes before committing staged files in the repository. In this case it will allow us to inspect the snapshot thatâ€™s about to be committed and see if it meets our code quality standards. Pre-commit hooks reside in local repositories within the <code>.git/hooks</code> directory.</p><p>Assuming that you already have a Git repository that contains a RAML Service Contract that youâ€™d like to <em>Lint</em>, let's begin by navigating to the <code>.git/hooks</code> directory and creating a file called <code>pre-commit</code><code></code>. Add the following contents to the file, replacing <code>&lt;main-raml-file-path&gt;</code> with the path to your main RAML file:</p><pre><code>#!/bin/sh
echo <span class="string">"# Running RAML Enforcer"</span>
sudo docker run \
  --<span class="keyword">init</span> --rm \
  --volume $(pwd):/tmp <span class="string">"mikeyryan/raml-enforcer:latest"</span> \
  /tmp/&lt;main-raml-file-path&gt;
</code></pre><p>Hooks need to be executable, so you may need to change the file permissions of <code>pre-commit</code> if you're creating it from scratch. You can do so by running the following command:</p><pre><code>chmod +x pre-commit
</code></pre><h2>Seeing it in action</h2><p>Now that we have a pre-commit hook in place for our repository, lets see how it looks! Make a change to your RAML Service Contract, then try and commit it. You should see a report like this printed to the screen:</p><img src="https://jimlearning.github.io/images/posts/git-hook-linter-commit.svg" alt="Git hook screenshot"/><p>When <em>RAML Enforcer</em> detects that the Service Contract contains errors or does not meet code standards, it prevents your staged files from being committed.</p><h2>Further reading</h2><ul><li><a href="https://www.atlassian.com/git/tutorials/git-hooks">Atlassian - Git hooks</a></li><li><a href="https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks">Customising Git - Git Hooks</a></li></ul>]]></content:encoded></item><item><guid isPermaLink="true">https://jimlearning.github.io/articles/npm-script-docker-image</guid><title>Containerising a Node.js script</title><description>When working inside a Continuous Integration (CI) and Continuous Delivery (CD) environment, portability of code is often a core concern that needs to be addressed. Developers write code locally and need some level of assurance that it will run consistently regardless of where it is deployed. This is an area where Docker shines. The goal of this post is to run a script, written with Node.js, inside a docker container. It assumes that you have an existing script which requires access to files on the local file system as well as an account on Docker Hub.</description><link>https://jimlearning.github.io/articles/npm-script-docker-image</link><pubDate>Fri, 17 May 2019 19:11:00 +0800</pubDate><content:encoded><![CDATA[<h2>Docker concepts</h2><p>To begin with, it's important to understand what Docker is and the principles behind it. Docker is a platform for <em>developers</em> and <em>system administrators</em> to develop, deploy and run applications with containers. The use of containers to deploy applications is called containerization, which is popular in CI and CD workflows because containers are<sup>[1]</sup>:</p><ul><li>Flexible - Any application can be containerized</li><li>Lightweight - They leverage and share the host kernel</li><li>Interchangeable - You can deploy updates and upgrades with zero down time</li><li>Portable - You can build locally and deploy to a server on premises or in the cloud</li><li>Scalable - You can scale your containers horizontally; increasing, decreasing or distributing replicas of them automatically</li><li>Stackable - You can stack your containers vertically, defining a stack declaratively</li></ul><p>In Docker a container is launched by running an image, and an image is an executable package that includes everything needed to run an application.</p><h2>Great.. so how do we create an image?</h2><p>To begin with, we will need to create file called <code>Dockerfile</code> in our working directory. A Dockerfile has a file format that contains instructions and arguments, which define the contents and startup behaviour of the Docker container. To run a Node.js script, our Dockerfile will need to contain the following, replacing <code>&lt;script-name&gt;</code> with the filename of your script:</p><pre><code># <span class="type">The</span> first instruction <span class="keyword">in</span> a <span class="type">Dockerfile</span> must be <span class="type">FROM</span>, which selects a base image. <span class="type">Since</span> it's recommended to use official <span class="type">Docker</span> images, we will use the official image <span class="keyword">for</span> node. <span class="type">We</span> will chose a specific image rather than defaulting to latest <span class="keyword">as</span> future node versions may <span class="keyword">break</span> our application.
<span class="type">FROM</span> node:<span class="number">12</span>-alpine

# <span class="type">Sets</span> the working directory to /usr/src/app.
<span class="type">WORKDIR</span> /usr/src/app

# <span class="type">Copies</span> the package file <span class="keyword">for</span> <span class="type">NPM</span> to the working directory.
<span class="type">COPY</span> package*.json ./

# <span class="type">Installs</span> the <span class="keyword">required</span> <span class="type">NPM</span> packages.
<span class="type">RUN</span> npm install

# <span class="type">Copies</span> the application from the current directory to the working directory of the image.
copy . .

# <span class="type">If</span> an action does not use the runs configuration option, the commands <span class="keyword">in</span> <span class="type">ENTRYPOINT</span> will execute. <span class="type">The Docker ENTRYPOINT</span> instruction has a shell form and exec form. <span class="type">We</span> will use the exec form of the <span class="type">ENTRYPOINT</span> instruction to call our node script. <span class="type">This</span> will allow us to pass arguments to the script when we run the container.
<span class="type">ENTRYPOINT</span> [<span class="string">"node"</span>, <span class="string">"&lt;script-name&gt;"</span>]
</code></pre><p>So the above <code>Dockerfile</code> will create a new image based on the official Node image, install our scripts NPM dependancies, copy the script to a working directory and when a container is started, automatically run the script. One thing we have overlooked is that since the <code>Dockerfile</code> installs NPM dependancies for us we shouldn't copy any node_modules into the image. To avoid this we can create a file called <code>.dockerignore</code> with the following contents:</p><pre><code>node_modules
</code></pre><p>With our <code>Dockerfile</code> and <code>.dockerignore</code> files in place, we can now build our image by running the following command and replacing <code>&lt;docker-hub-username&gt;</code> with your Docker Hub username and <code>&lt;image-name&gt;</code> with something memorable:</p><pre><code>sudo docker build \
  --no-cache \
  --tag <span class="string">"&lt;docker-hub-username&gt;/&lt;image-name&gt;:latest"</span> .
</code></pre><img src="https://jimlearning.github.io/images/posts/npm-script-docker-build.svg" alt="Docker build screenshot"/><h2>Running our image</h2><p>Having built a Docker image, we can now run it locally by using the following command and replacing <code>&lt;docker-hub-username&gt;</code> with your Docker Hub username and <code>&lt;image-name&gt;</code> with the name used earlier:</p><pre><code>sudo docker run \
  --<span class="keyword">init</span> --rm \
  --volume $(pwd):/tmp \
  <span class="string">"&lt;docker-hub-username&gt;/&lt;image-name&gt;:latest"</span> &lt;image-args&gt;
</code></pre><img src="https://jimlearning.github.io/images/posts/npm-script-docker-run.svg" alt="Docker run screenshot"/><p>For reference, the arguments we are passing through to Docker are:</p><ul><li><strong>init</strong>: sets the ENTRYPOINT to tini. tini is a lightweight init process which will help ensure that Node.js returns and responds to signals correctly</li><li><strong>rm</strong>: removes the container once it has finished running</li><li><strong>volume</strong>: mounts the specified location inside the container</li></ul><h2>Pushing our image to Docker Hub</h2><p>The final step of our journey is to publish our local docker image to Docker Hub so that we are able to pull and run it from other locations such as a CI/CD server. Before we can push our image we will need to login do Docker Hub by running the following command and entering our Docker Hub username and password when prompted:</p><pre><code>docker login
</code></pre><p>Once successfully authenticated, we can push our image by running the following command and replacing <code>&lt;docker-hub-username&gt;</code> with your Docker Hub username and <code>&lt;image-name&gt;</code> with the name used earlier:</p><pre><code>sudo docker \
  push <span class="string">"&lt;docker-hub-username&gt;/&lt;image-name&gt;:latest"</span>
</code></pre><img src="https://jimlearning.github.io/images/posts/npm-script-docker-push.svg" alt="Docker push screenshot"/><p>Thats it! You can navigate to <code>https://hub.docker.com/r/&lt;docker-hub-username&gt;/&lt;image-name&gt;</code> to see your published image.</p><h2>References</h2><ul><li><a href="https://docs.docker.com/get-started/        "Docker"">Docker - Get Started</a></li></ul>]]></content:encoded></item><item><guid isPermaLink="true">https://jimlearning.github.io/articles/kubernetes-with-dashboard</guid><title>Setup Kubernetes and its dashboard on Docker Desktop</title><description>In this post we will walk through how you can install and run a single node Kubernetes instance using Docker Desktop Community Edition for Windows or Mac.</description><link>https://jimlearning.github.io/articles/kubernetes-with-dashboard</link><pubDate>Thu, 16 May 2019 21:41:00 +0800</pubDate><content:encoded><![CDATA[<h2>Prerequisites</h2><p>To keep things simple, we will assume you have access to a bash Command Line Interface (CLI) on your local machine. Mac users should have access to the <em>Terminal</em> application while Windows users will need to install one of several options, including but not limited to:</p><ul><li><a href="https://docs.microsoft.com/en-us/windows/wsl/install-win10">Windows subsystem for Linux</a></li><li><a href="https://gitforwindows.org">Git for Windows (Git Bash)</a></li></ul><h2>What is Kubernetes</h2><p>Kubernetes (K8s) is a portable open source platform for automating the deployment, scaling and management of containerised applications. The name Kubernetes originates from the Greek language, meaning helmsman or pilot and is the root of the words governor and cybernetic. It emerged from the need for declarative configuration for the orchestration of containers, which had just been popularised by Docker. Although Docker provided a simple way to package, distributed and deploy applications, its focus on single machine left a gap for management at enterprise or cloud scales.</p><p>K8s can be thought of as:</p><ul><li>a container platform;</li><li>a microservices platform; and</li><li>a portable cloud platform.</li></ul><p>It's ability to orchestrate computing, networking, and storage infrastructure on behalf of user workloads makes it particularly well suited for hosting distributed applications such as an Enterprise Service Bus (ESB).</p><h2>Install Docker Desktop</h2><img src="https://jimlearning.github.io/images/posts/docker-logo.svg" alt="Docker logo"/><p>If you want to get started with Kubernetes on a Windows 10 or Mac OS operating system, Docker Desktop is the quickest way. Docker Desktop comes in two editions, a free community edition and a paid enterprise edition. It includes everything you need to build, test and ship containerised applications right from your machine and for this walkthrough, either edition will be suitable. To obtain a copy, head to the <a href="https://www.docker.com/products/docker-desktop">Docker website</a>, and follow the instructions to download and install it.</p><p>Once installed, you can verify that Docker is up and running by opening your CLI of choice and executing the following command:</p><pre><code>docker version
</code></pre><p>If successful, you should seen some output printed to the screen similar to this:</p><pre><code><span class="type">Client</span>: <span class="type">Docker Engine</span> - <span class="type">Community
 Version</span>:           <span class="number">18.09.2</span>
 <span class="type">API</span> version:       <span class="number">1.39</span>
 <span class="type">Go</span> version:        go1.<span class="number">10.8</span>
 <span class="type">Git</span> commit:        <span class="number">6247962</span>
 <span class="type">Built</span>:             <span class="type">Sun Feb</span> <span class="number">10 04</span>:<span class="number">12</span>:<span class="number">39 2019</span>
 <span class="type">OS</span>/<span class="type">Arch</span>:           darwin/amd64
 <span class="type">Experimental</span>:      <span class="keyword">false</span>

<span class="type">Server</span>: <span class="type">Docker Engine</span> - <span class="type">Community
 Engine</span>:
  <span class="type">Version</span>:          <span class="number">18.09.2</span>
  <span class="type">API</span> version:      <span class="number">1.39</span> (minimum version <span class="number">1.12</span>)
  <span class="type">Go</span> version:       go1.<span class="number">10.6</span>
  <span class="type">Git</span> commit:       <span class="number">6247962</span>
  <span class="type">Built</span>:            <span class="type">Sun Feb</span> <span class="number">10 04</span>:<span class="number">13</span>:<span class="number">06 2019</span>
  <span class="type">OS</span>/<span class="type">Arch</span>:          linux/amd64
  <span class="type">Experimental</span>:     <span class="keyword">true</span>
 <span class="type">Kubernetes</span>:
  <span class="type">Version</span>:          v1.<span class="number">10.11</span>
  <span class="type">StackAPI</span>:         v1beta2
</code></pre><h2>Install Kubernetes</h2><img src="https://jimlearning.github.io/images/posts/kubernetes-logo.svg" alt="Kubernetes logo"/><p>Once Docker Desktop is installed, you should see a whale icon in the taskbar for Windows or the menu bar for Mac. Clicking the icon should reveal a content menu with an option for <em>Settings</em> or <em>Preferences</em> depending on your Operating System, select it. Once open, navigate to the Kubernetes tab. Kubernetes is not installed by Docker Desktop by default, you'll need to check the <em>Enable Kubernetes</em> checkbox and wait for it to be downloaded and installed before proceeding. The amount of time this will take largely depends on your internet speed, once the window shows <em>Kubernetes is running</em>, you should be ready to continue.</p><p>Once enabled, you can verify that Kubernetes is available by opening your CLI of choice and executing the following command:</p><pre><code>kubectl version
</code></pre><p>If successful, you should seen some output printed to the screen similar to this:</p><pre><code><span class="type">Client Version</span>: version.<span class="type">Info</span>{<span class="type">Major</span>:<span class="string">"1"</span>, <span class="type">Minor</span>:<span class="string">"10"</span>, <span class="type">GitVersion</span>:<span class="string">"v1.10.11"</span>, <span class="type">GitCommit</span>:<span class="string">"637c7e288581ee40ab4ca210618a89a555b6e7e9"</span>, <span class="type">GitTreeState</span>:<span class="string">"clean"</span>, <span class="type">BuildDate</span>:<span class="string">"2018-11-26T14:38:32Z"</span>, <span class="type">GoVersion</span>:<span class="string">"go1.9.3"</span>, <span class="type">Compiler</span>:<span class="string">"gc"</span>, <span class="type">Platform</span>:<span class="string">"darwin/amd64"</span>}
<span class="type">Server Version</span>: version.<span class="type">Info</span>{<span class="type">Major</span>:<span class="string">"1"</span>, <span class="type">Minor</span>:<span class="string">"10"</span>, <span class="type">GitVersion</span>:<span class="string">"v1.10.11"</span>, <span class="type">GitCommit</span>:<span class="string">"637c7e288581ee40ab4ca210618a89a555b6e7e9"</span>, <span class="type">GitTreeState</span>:<span class="string">"clean"</span>, <span class="type">BuildDate</span>:<span class="string">"2018-11-26T14:25:46Z"</span>, <span class="type">GoVersion</span>:<span class="string">"go1.9.3"</span>, <span class="type">Compiler</span>:<span class="string">"gc"</span>, <span class="type">Platform</span>:<span class="string">"linux/amd64"</span>}
</code></pre><p>This will have resulted in Docker Desktop setting up a single node Kubernetes cluster on your local machine.</p><h2>Installing the Kubernetes Dashboard</h2><p>Dashboard is an official web-based user interface for Kubernetes. It can be used as an alternative to the CLI for those that prefer to work with a Graphical User Interface (GUI). At a high level, it features the ability to deploy, troubleshoot and manage resources for Kubernetes clusters. In particular, it can be used to get an overview of running applications and to perform common tasks such as scaling a deployment, initiate a rolling update, restarting a pod or deploying new applications.</p><p>Although the Dashboard is the official GUI for Kubernetes, it is not deployed by default. To deploy it to your single node Kubernetes cluster, run the following command:</p><pre><code>kubectl apply \
  -f https://raw.<span class="property">githubusercontent</span>.<span class="property">com</span>/kubernetes/dashboard/v2.<span class="number">0.0</span>-beta8/aio/deploy/recommended.<span class="property">yaml</span>
</code></pre><p>To make the deployed Dashboard accessible, use the kubectl command-line tool by running the following command:</p><pre><code>kubectl proxy
</code></pre><p>You will then be able to navigate to <a href="http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/">http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/</a> in your browser to access the dashboard.</p><h2>Setting up a Dashboard user</h2><p>Navigating to the Dashboard will have presented a screen asking for a Kubeconfig file or an access token. To use the Dashboard, you'll need to create a user and obtain a bearer token for them. Begin by creating a file called <code>dashboard-admin-user.yaml</code> with the following contents:</p><pre><code>apiVersion: v1
kind: <span class="type">ServiceAccount</span>
metadata:
  name: admin-user
  namespace: kube-system
</code></pre><p>Then navigate to the location you saved the file in your CLI and use the following command to create the admin user:</p><pre><code>kubectl apply \
  -f dashboard-admin-user.<span class="property">yaml</span>
</code></pre><p>Finally, to obtain a bearer token, you'll need to run the following command:</p><pre><code>kubectl -n kube-system describe secret \
  $(kubectl -n kube-system <span class="keyword">get</span> secret | grep admin-user | awk '{print $1}')
</code></pre><p>It should print some output to the screen like this:</p><pre><code><span class="type">Name</span>:         admin-user-token-m9nr5
<span class="type">Namespace</span>:    kube-system
<span class="type">Labels</span>:       &lt;none&gt;
<span class="type">Annotations</span>:  kubernetes.<span class="property">io</span>/service-account.<span class="property">name</span>=admin-user
              kubernetes.<span class="property">io</span>/service-account.<span class="property">uid</span>=b9b37a57-812d-11e9-<span class="number">9877</span>-<span class="number">025000000001</span>

<span class="type">Type</span>:  kubernetes.<span class="property">io</span>/service-account-token

<span class="type">Data</span>
====
ca.<span class="property">crt</span>:     <span class="number">1025</span> bytes
namespace:  <span class="number">11</span> bytes
token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.<span class="property">eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLW05bnI1Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJiOWIzN2E1Ny04MTJkLTExZTktOTg3Ny0wMjUwMDAwMDAwMDEiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06YWRtaW4tdXNlciJ9</span>.<span class="type">EZ37ihKfHBszN1Ujz6EgDj143Q</span>-hUKtWUyo1s88D0-<span class="type">WCwdtnmdZLUyvg4d5H6NmZo7AbrkPrNHXOLy45piU9ghQHejicz5SBLI_JtPFO68BxOiGv7MuNYAAHJO82y</span>-<span class="type">NNbTDjfx6Rbj9RK5</span>-pWoHO9eOSvHa-<span class="type">XDC0OH3Usj4gjjVdXhf5uBl3meKPtUwlaXX0ziaIMoDmfHLw43vqugpJDyNMXkcil0s0NzFFlPBLu4enPx_TEuJp0pKsBEKXDNgB9amSmljD7ovdNd9ocIA7kNBe3SSctTkqxYqOrABuaC3KDmCGzCOGRboDUJEL8FP3HtbimsXCm8jXKzqo</span>-5a_YA
</code></pre><h2>Accessing the Dashboard</h2><p>Copy the token that was printed to the screen, navigate back to the browser window we opened earlier and select the option <em>Token</em>. Paste the token into the password field shown on the screen and press the <em>Sign in</em> button. Thatâ€™s it! You should now be able to access Kubernetes Dashboard as shown below:</p><img src="https://jimlearning.github.io/images/posts/kubernetes-dashboard.png" alt="Kubernetes Dashboard"/><h2>References</h2><ul><li><a href="https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/ "Web UI (Dashboard)"">Web UI (Dashboard)</a></li><li><a href="https://github.com/kubernetes/dashboard/wiki/Creating-sample-user "Creating sample user"">Creating sample user</a></li><li><a href="https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/ "What is kubernetes"">What is Kubernetes</a></li></ul>]]></content:encoded></item><item><guid isPermaLink="true">https://jimlearning.github.io/articles/linting-RAML</guid><title>Linting RESTful API Modelling Language (RAML)</title><description>Within a Continuous Integration (CI) and Continuous Delivery (CD) environment, the first principles is that no code is delivered without automated tests. Today we are going to look at this principle and how we can easily identify and correct common  coding mistakes when designing Service Contracts for Application Programming Interfaces (APIs). Specifically, we will explore how Linting can be used for this purpose.</description><link>https://jimlearning.github.io/articles/linting-RAML</link><pubDate>Thu, 16 May 2019 21:41:00 +0800</pubDate><content:encoded><![CDATA[<h2>What is Linting</h2><p><em>Linting</em> is the process of using a tool to examine source code for programatic errors, bugs, stylistic errors or suspicious patterns. A <em>Linter</em> or <em>Lint</em> is a piece of software that supports verifying code quality through <em>Linting</em>. Most Linters are highly configurable and extensible, allowing developers to select from a set of prepackaged rules to enforce a particular coding standard, or to invent their own rules as needed.</p><p>In a CI toolchain, <em>Linting</em> is performed very early in the workflow, usually prior to running unit tests. It is often implemented on the local development machine inside of a pre-commit in distributed Version Control Systems such as <em>Git</em> to reject code that does not pass the <em>Linter</em> code quality checks. It can also be enforced as part of stage within the build process.</p><h2>Where does Linting come from?</h2><p><em>Lint</em> was the name of a program written in 1978 by Stephen Johnson at Bell LabsÂ to identify problems with C source code before complication and runtime. It was later used in 1979 inside the seventh version of the UnixÂ operating system. Over time the term <em>Lint</em> became a verb that meant checking your source code.</p><h2>So... why Lint your Service Contracts?</h2><p>Whether you're implementing a Service Layer, Enterprise Service Bus or Application Network, as your API progresses through the various stages of development, code quality becomes critical. Collaborating with your customers to ensure that the design of an API meets functional requirements is a given, but it's also important to ensure that it doesn't include any structural issues. A poorly structured API can impact the reliability and efficiency of its consumers as well as make the implementation harder. For those employ a micro-services architecture or find themselves working with large teams, a consistent approach to the design of APIs is particularly important for maintainability.</p><p><em>Linting</em> can be used to find and resolve both functional and structural issues with an API'cs Service Contract. It can identify and correct common code mistakes without having to run your code or execute tests. Some of the key benefits a <em>Linter</em> provides you with include:</p><ul><li>Avoiding errors - they give you immediate feedback about things that look like errors or could potentially be dangerous</li><li>Readability - they can drive you to write cleaner and more constant code</li><li>Maintainability - they can be used to help developers working as part of a team to adhere to a uniform coding standards</li><li>Portability - they can be used within an IDE, text editors such as Visual Studio Code, a command line and continuous integration tools</li><li>Automatic fixes - using a prettier they can enabling code style issues to be fixed automatically</li></ul><h2>Integrating Linting into your RAML Service Contract</h2><p>Unfortunately, at the time of writing most of the RAML <em>Linters</em> available are just wrapping an open source parser. Parsing RAML helps to identify errors, but does little in the way of improving the readability or maintainability of your Service Contracts. This is why I decided to build my own <em>Linter</em>, called <em>RAML Enforcer</em>. <em>RAML Enforcer</em> is a command line tool for identifying and reporting on patterns found within RAML code. It supports, RAML 0.8, RAML 1.0, Includes and Fragments.</p><p>Although there are a few different options for running <em>RAML Enforcer</em>, in this case we will build and run it directly from the source code. To get up and running you'll need to ensure you have Git, Node.js and NPM installed on your local machine. Once you have them, you can begin by opening up your Command Line Interface (CLI) of choice and using it to clone the source code of the project from GitHub:</p><pre><code>git clone https://github.<span class="property">com</span>/<span class="type">Mike</span>-<span class="type">Gough</span>/raml-enforcer
</code></pre><p>Next, you will need to navigate to the repository we just cloned and install the required dependancies for <em>RAML Enforcer</em> by running the following command:</p><pre><code>cd raml-enforcer &amp;&amp; \
  npm install
</code></pre><p>Finally, you can execute the <em>Linter</em> by using the following command, replacing <code>main-api-file</code> with the path to the main RAML file for your service contract:</p><pre><code>node raml-enforcer.<span class="property">js</span> &lt;main-api-file&gt;
</code></pre><p>The result will be a report which identifies errors and highlights styling issues:</p><img src="https://jimlearning.github.io/images/posts/raml-enforcer-report.svg" alt="RAML Enforcer Report"/><p>In a future post, we will look at how <em>RAML Enforcer</em> can be used in a pre-commit hook.</p>]]></content:encoded></item><item><guid isPermaLink="true">https://jimlearning.github.io/articles/hello-world</guid><title>Hello World</title><description>The internet is full of how-to guides for architects and software developers, this blog is not one of them.</description><link>https://jimlearning.github.io/articles/hello-world</link><pubDate>Wed, 15 May 2019 17:17:00 +0800</pubDate><content:encoded><![CDATA[<p>I offer by way of explanation, a tale of integrating software. I intend to use this space to document the many projects and prototypes I work on for later reference.</p><p>I've chosen to make it public so that it might be of some benefit to other architects, software developers and technologists. Along the way I'll share my endeavour to make something useful and lasting whilst being stymied by obstacles both old and new.</p>]]></content:encoded></item></channel></rss>